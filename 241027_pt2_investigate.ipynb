{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from typing import *\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 20)\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.w1 = nn.Parameter(torch.randn(20, 10))\n",
    "        self.w2 = nn.Parameter(torch.randn(10, 20))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if x.sum() > 0:\n",
    "        #     return x\n",
    "        # x += 1\n",
    "        z = self.fc.weight\n",
    "        # return x @ z.T + self.fc.bias\n",
    "        # x = torch.lerp(x, torch.zeros_like(x), 0.5)\n",
    "        # return x + torch.zeros_like(z).sum() + self.fc(x).sum()\n",
    "        # x = x + x.abs()\n",
    "        x = self.fc(x)\n",
    "        x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
    "        y = self.w1.pow(2)\n",
    "        x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
    "        return self.fc(x[..., :10].abs()).mean() + self.fc2(x).mean()\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.arange(1, 100)\n",
    "\n",
    "plt.plot(x, (1 + 1/ x)** x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1608694625.py, line 198)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[60], line 198\u001b[0;36m\u001b[0m\n\u001b[0;31m    Each tensor should have\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "r'''\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "[ NOTE ] Assumption: Alignment in neural nets\n",
    "\n",
    "Alignment refers to the phenomenon that, as learning progresses, the operator inputs often nearly attains the op-norm\n",
    "bound for the weight matrices [1] or weight updates [2].\n",
    "\n",
    "Therefore, the usual \"gaussian random input\" assumption is violated. Hence, when we consider an intermediate tensor\n",
    "being in a norm ball, we generally assume that it lives on the shell and attains the norm ball bound. (!important)\n",
    "\n",
    "Furthermore, in computing operator norms, we often assume that its entries are \"balancedly distributed\", e.g., has\n",
    "balanced signs for ReLU. It remains an open question on how this is consistent with the alignment phenomenon.\n",
    "\n",
    "NOTE that however, we do not make this assumption for the perturbations of weights or inputs.\n",
    "\n",
    "[1] Scaling Exponents Across Parameterizations and Optimizers\n",
    "[2] A Spectral Condition for Feature Learning\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "[ NOTE ] PT2 converted graph and Modula\n",
    "\n",
    "There are two things in a PT2 converted graph (we use torch.export):\n",
    "    1. A module, represented as f(x; w), with certain traits set so we can reason about the parameter\n",
    "    2. An op, represented as f(x), enforced to be an ATen core op (`torch.ops.aten.*`) see https://pytorch.org/docs/main/torch.compiler_ir.html#core-aten-ir\n",
    "\n",
    "The goal of modula conversion is to reason about norms so that all modules and ops become \"well-normed\". In original modula, a module is\n",
    "single-input, single-output, single-paramter operator, defined with f(x: Tensor | TensorList, w: Tensor) -> y: Tensor, with a few addition constants\n",
    "set so that it is well-normed (depending on the operation in f, and the norm spaces placed on x and y). And an op is a parameter-less module.\n",
    "\n",
    "    To handle the general case, there is a special multi-input single-output operator Concat(*args) -> args that essentially just takes a few inputs and\n",
    "    return the list that contains them. Its norm is the l1 sum of each element's norm.\n",
    "\n",
    "Assuming the reader understands the modula paper, we now discuss the most important difference we need to handle:\n",
    "\n",
    "    How do we handle complex modules with multi-input, multi-param, multi-output? What does mass, sensitivity attach to?\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "[ NOTE ] The API of PT2 Modula\n",
    "\n",
    "THE TRICKY PART is that we want to support the multi-input, multi-param, multi-output case.\n",
    "\n",
    "THE KEY APIs, on a high-level,are:\n",
    "    + TensorMeta\n",
    "    + ParamMeta(TensorMeta)\n",
    "    + SimpleOpMeta, a multi-input, multi-param, single-output operator\n",
    "    + ModuleMeta, containing multiple ParamMetas and multiple SimpleOpMetas. NOT attached to any particular input/output.\n",
    "    + NodeMeta, containing a SimpleOpMeta, multiple ParamMetas, and multiple TensorMetas (inputs). Attached to a particular input/output pair.\n",
    "\n",
    "'''\n",
    "@attrs.define(kw_only=True)\n",
    "class TensorMeta:\n",
    "    # A tensor is either a parameter or an intermediate (eg, output of an operator).\n",
    "    #\n",
    "    # This defines the norm SPACE of a tensor.\n",
    "\n",
    "    # The NORM of a tensor is defined by its norm_kind (one of rms, l1, l2, or operator-norm between two spaces)\n",
    "    norm_kind: str\n",
    "\n",
    "    # NORM_SIZE is the size of the tensor (assuming alignment, see [ NOTE ] Assumption: Alignment in neural nets)\n",
    "    norm_size: float = 1\n",
    "\n",
    "\n",
    "@attrs.define(kw_only=True)\n",
    "class ParamMeta(TensorMeta):\n",
    "    state_dict_key: str  # the key in state_dict of the full module\n",
    "\n",
    "    # How much feature learning is attributed to this paramter: under maximal update, how much output changes with 1 update on this parameter\n",
    "    mass: float\n",
    "\n",
    "\n",
    "@attrs.define(kw_only=True)\n",
    "class SimpleOpMeta:\n",
    "\n",
    "    @attrs.define(kw_only=True)\n",
    "    class BoundSimpleOpMeta:\n",
    "        args_spec: Tuple[pytree[TensorMeta], ...]\n",
    "        kwargs_spec: pytree[TensorMeta]\n",
    "        param_spec: pytree[ParamMeta]\n",
    "        out_spec: TensorMeta\n",
    "        op_norm_bound: float\n",
    "\n",
    "    def meta_forward(self, args_spec: Tuple[pytree[TensorMeta], ...], kwargs_spec: pytree[TensorMeta], param_spec: pytree[ParamMeta]) -> (TensorMeta, float):\n",
    "\n",
    "\n",
    "    + MASS is a per-parameter concept:\n",
    "        + How much feature learning is attributed to this paramter: under maximal update, how much output changes with 1 update on this parameter\n",
    "\n",
    "    + Each OUTPUT of a MODULE is viewed as a SINGLE-OUTPUT OPERATOR (SOOp for short).\n",
    "        + All SOOps of a MODULE share the same INPUTs and PARAMETERs.\n",
    "        + Given {input} and {param} (with all the norm information above), we can compute the norm information for the output.\n",
    "\n",
    "    + SENSITIVITY is a per-(SOOp x INPUT) concept (ie, per-OUTPUT-per-INPUT):\n",
    "        + Bounds the SOOp's sensitivity to INPUT perturbations, i.e., the op-norm bound of the SOOp.\n",
    "\n",
    "        + Input is assumed to be uniformly distributed on a certain norm sphere (see [ NOTE ] Assumption: Alignment in neural nets).\n",
    "\n",
    "        + This generally depends on {parameter.norm_size}.\n",
    "\n",
    "        + Sometimes the _uniform distribution on norm sphere_ assumption is crucial to compute the senstivity in a reasonable and consistent way.\n",
    "           + If we instead consider the full norm ball, some op could have arbitarily large sensitivity, e.g., AddBias with near zero input.\n",
    "           + If we do not assume uniform distribution, some op would have different sensitivity, e.g., ReLU would have sensitivity 1 rather than 0.5, which\n",
    "             is likely too loose since it implies that the network always operates in the linear regime.\n",
    "\n",
    "    + OP_NORM_COEFF is a per-(SOOp x PARAMETER) concept (ie, per-OUTPUT-per-PARAMETER):\n",
    "        + Defines the bound of SOOp's sensitivity to PARAMETER perturbations.\n",
    "\n",
    "          In particular, it defines a NORM over the parameter space, under which the SOOp is Lip-1 over parameters for any input.\n",
    "          Equivalently, it is a norm over W such that the set of linear maps {\\nabla_w op(x, w)}_{x,w} all have operator norm at most 1.\n",
    "\n",
    "          For examples,\n",
    "            1. a linear layer without bias has linear maps { \\nabla_W Wx }_{x,W} = { x }, where each map is defined\n",
    "               as W -> Wx. For input space X := rho * unit RMS ball. The output (RMS) norm is rho * ||W||_rms-rms, so it is a valid choice.\n",
    "            2. an add bias operation has linear maps { \\nabla_b (x+b) }_{x,b} = { I }, where each map is defined\n",
    "               as b -> b. The output (RMS) norm is ||b||_rms, so it is a valid choice.\n",
    "\n",
    "        + As seen above, this norm\n",
    "            + generally depends on {input.norm_size}, e.g., to determine the scale of the ||W||\n",
    "            + does not depend on {parameter.norm_size} when the operation is linear in the parameter\n",
    "\n",
    "        + Each SOOp is assumed to be \"primitive\" enough so that this norm can be written as a weighted MAX combination\n",
    "          of parameter norms `max(b1 ||W1||, ...)`.\n",
    "\n",
    "          Unlike SENSITIVITY, this uses a weighted MAX combination of parameter norms. According to @jbxz:\n",
    "\n",
    "                > Two reasons for this. Taking M.norm to be max rather than sum\n",
    "                > 1. gives much tighter sharpness bounds in M.norm\n",
    "                > 2. induces a \"duality map\" that leads to training all layers every step. The sum combination would only update\n",
    "                >    one layer per step which feels unnatural\n",
    "\n",
    "        + Our goal is to compute the {b_i}_i, for each SOOp (ie, each output).\n",
    "\n",
    "        + For a composed operation, e.g., linear := add_bias \\circ matmul_weight, the key for computing these {b_i}_i is to\n",
    "\n",
    "            + Assume that other ops attain their upper bounds. Therefore, there is no higher order terms. (*)\n",
    "\n",
    "            + When each sub-op has valid param norm, we can compose them together using weighted MAX:\n",
    "\n",
    "                (M2 \\circ M1).norm((W1, W2)) := max(\n",
    "                    M2.sensitivity * (total_mass/mass_1) * ||W1|| * possible_op_dependent_scale_for_w1,\n",
    "                                     (total_mass/mass_2) * ||W2|| * possible_op_dependent_scale_for_w2,\n",
    "                )\n",
    "\n",
    "              (max_over_sum: note that \\max(p x1, q x2) \\geq x1 + x2, if p + q = 1, which extends to multiple terms easily.)\n",
    "\n",
    "              In general, ||W1|| depends on the input and output norm spaces of M1, and `possible_op_dependent_scale_for_w1`\n",
    "              depends on the norm_size of input to M1.\n",
    "\n",
    "              In original jbxz/modula repo, this is wildly simplified\n",
    "                1. all atoms assume unit-norm input\n",
    "                2. some modules do not output unit-norm tensors\n",
    "                3. they usually have scaled versions that do.\n",
    "\n",
    "              They only use modules of the first and the last type.\n",
    "\n",
    "              We will do the general thing since we track {input.norm_size}.\n",
    "\n",
    "        + (max_over_sum) may be helpful to come up with proper {b_i}_i.\n",
    "\n",
    "        + The modula way to handle multi-input and multi-parameter is to conceptually use a Concat module, which employs\n",
    "          the SUM-reduced norm on concatenated tensors and the mass-weighted MAX-reduced norm on parameters.\n",
    "\n",
    "    + SENSITIVITY and OP_NORM_COEFF together define the op-norm bound of composed modules / chained ops because we ignore\n",
    "      higher-order terms (see (*)).\n",
    "\n",
    "      In particular, we chain things together using (chain_w_unit_input) or (chain_w_propagated_input), depending on the global OpNormMode.\n",
    "\n",
    "A PARAMETER is a tensor with tunable MASS and NORM_BOUND.                                                        # ParamMeta\n",
    "\n",
    "An SINGLE-OUTPUT OPERATOR (SOOp for short) has\n",
    "    + forward(args, params) -> one_out_tensor, and                                                               # SingleOutputOpMeta\n",
    "    + forward_meta(arg_meta_fns: List[Callable[[], TensorMeta]], param_metas) -> (out_tensor_meta, float[param_metas]).\n",
    "\n",
    "        The RVs are out_tensor_meta: TensorMeta and op_norm_coeffs: float, where the float is the op-norm bound of the SOOp.\n",
    "\n",
    "        We use callables rather than materialized TensorMeta to defer the computation that could depend on\n",
    "        some parameters' MASS and NORM_BOUND, so that eventually we can build a \"pure\" function that\n",
    "        maps parameters' MASS and NORM_BOUND to objects of interest.\n",
    "\n",
    "        See [ NOTE ] Our goal below.\n",
    "\n",
    "A MODULE consists of essentially                                                                                 # ModuleMeta\n",
    "    + a collection of paramters as a pytree[ParamMeta]\n",
    "    + a collection of SOOps as a pytree[SingleOutputOpMeta], one for each output Tensor.\n",
    "\n",
    "        Then, given `arg_meta_fns`, we can build a `Callable[[], out_tensor_meta]` for each output tensor, which\n",
    "        can then be used as input to the next operator\n",
    "\n",
    "    + forward_meta(arg_meta_fns: List[Callable[[], TensorMeta]], param_metas) -> pytree[Callable[[], TensorMeta]]\n",
    "      as defined above.\n",
    "\n",
    "We provide support for the following MODULEs (incl. ops):\n",
    "    + `nn.Linear`\n",
    "    + `nn.LayerNorm`\n",
    "    + `nn.MultiheadAttention`\n",
    "    + `torch.ops.aten.matmul`\n",
    "    + `torch.ops.aten.add`\n",
    "    + `torch.ops.aten.mul`\n",
    "    + `torch.ops.aten.relu`\n",
    "    + `torch.ops.aten.gelu`\n",
    "\n",
    "We use PT2 to get fx.Graph that consists of the above modules and ops (along with `getitem`).\n",
    "Each fx.Node.meta['modula'] contains the following:                                                               # NodeMeta\n",
    "    + `module`: ModuleMeta\n",
    "    + `out_meta_fn`: Callable[[], TensorMeta]\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "[ NOTE ] Our goal:\n",
    "\n",
    "Given a PT2 converted graph, generate a computation mapping that takes in\n",
    "    + {parameter.op_norm_bound} and {parameter.mass} for each parameter\n",
    "produces\n",
    "    + {output.op_norm_bound} for each output\n",
    "    +\n",
    "1. generate a computation mapping from {parameter.op_norm_bound} and {parameter.mass} to {output.op_norm_bound}\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "[ NOTE ] Modules with alternative computation defintions: e.g., biased linear modules\n",
    "\n",
    "There are, as usual, multiple ways to define a module computation and thus the norms. E.g., a biased linear module can\n",
    "be viewed as either\n",
    "  MatMul \\circ AppendOne\n",
    "OR\n",
    "  AddBias \\circ MatMul\n",
    "\n",
    "Some of these formulations may be nicer than others. E.g., AddBias does not have bounded op-norm. Now the modula way\n",
    "is to assume input has some certain constaint bounded norm, and derive an op-norm by division (e.g., RMSDivide in eq B.14).\n",
    "\n",
    "We do three modes: OpNormMode.EXACT_BOUND, OpNormMode.EST_FROM_UNIT_INPUT, OpNormMode.EST_FROM_PROPAGATED_INPUT. Names\n",
    "are self-explanatory, and the modula default is OpNormMode.EST_FROM_UNIT_INPUT. And EXACT_BOUND should work for all inputs,\n",
    "but could error out.\n",
    "\n",
    "To support different ways to formulate parameters for biased linear modules, we provide a flag\n",
    "\n",
    "THIS MEANS THAT FOR BIASED LINEAR MODULES, we consider it as MatMul \\circ AppendOne. The alternative, which uses AddBias,\n",
    "does not have bounded op-norm. This means that we consider parameters in a possibly different way than state dict. Hence,\n",
    "we consider a concept called param_dict, which is the parameters suitable for Modula. We implement this modification for\n",
    "(1) nn.Linear (2) nn.LayerNorm (where .weight has Linf as op norm) (3) nn.Conv2d. But it can be generally extended, if needed.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "now there is one important possible traits of modules:\n",
    "1. ($*$) scale-flex (general), for any w, alpha, exists w' s.t. for any x, alpha f(x, w) = f(x, w'). e.g., conv, fc, etc\n",
    "\n",
    "in practice, we will just focus on ones that transfer the scale to w', i.e., linear in w:\n",
    "1. scale-flex, for any w, alpha, for any x, alpha f(x, w) = f(x, alpha w'). e.g., conv, fc, etc\n",
    "\n",
    "\n",
    "there is one important possible traits of modules & ops\n",
    "2. scale-inv, for any w, for any x, alpha, f(x) = f(alpha x), e.g., layer norm, rmsnorm\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "Each tensor should have\n",
    "```py\n",
    "class TensorMeta:\n",
    "    # we consider scaled versions of a few norms\n",
    "    # i.e., ||x|| := ||x||_norm_kind * norm_scale\n",
    "    norm_kind: str               # [rms, l1, l2, or *-*]\n",
    "    norm_scale: float = 1\n",
    "\n",
    "    mass: Optional[Tensor]       # set iff this is parameter, see\n",
    "    norm_size: float = 1         # Size of current tensor, settable iff is_parameter.\n",
    "\n",
    "    tensor_meta: FakeTensor\n",
    "\n",
    "    def to(self, other: TensorMeta) -> TensorMeta:\n",
    "        # if just rescaled version of other, convert norm_bound so that we have other.norm_kind, other.norm_scale\n",
    "        ...\n",
    "```\n",
    "\n",
    "Each node should have (see later for more)\n",
    "```py\n",
    "class NodeMeta:\n",
    "    components: pytree[TensorMeta]\n",
    "```\n",
    "\n",
    "We define\n",
    "```py\n",
    "def norm(tensors: pytree[Tensor], meta: pytree[TensorMeta], *, dual: bool = False, dualized: Optional[pytree[Tensor]] = None) -> pytree[float]:\n",
    "    # support rms, l1, l2, l2-l2 (spec), rms-rms (scaled spec), l1-rms, nuclear\n",
    "    ...\n",
    "\n",
    "def initialize_with_maximal_unit_norm(meta: pytree[TensorMeta]) -> pytree[Tensor]:\n",
    "    ...\n",
    "\n",
    "def dualize(tensors: pytree[Tensor], meta: pytree[TensorMeta]) -> pytree[Tensor]:\n",
    "    ...\n",
    "```\n",
    "\n",
    "NB: the modula norm, operating on a state-dict-like collection of weights (except it is on param dicts that could possibly differ, see ModuleMeta),\n",
    "is essentially a `pytree[TensorMeta]`, defined as\n",
    "```py\n",
    "class ModulaNorm:\n",
    "    comp_spec: pytree[TensorMeta]\n",
    "\n",
    "    def state_dict_to_param_dict(self, pytree[ModuleMeta], pytree[Tensor]) -> Tensor[param_spec]:\n",
    "        ...\n",
    "\n",
    "    def param_dict_to_state_dict(self, pytree[ModuleMeta], Tensor[param_spec]) ->  pytree[Tensor]:\n",
    "        ...\n",
    "\n",
    "\n",
    "    def norm(self, tensors: Tensor[comp_spec], dual: bool = False, dualized: Optional[pytree[Tensor]] = None) -> float:\n",
    "        # reduction is max, dual of that is sum (ie, l1 linf) (TODO: support different reduction at different levels?)\n",
    "        ...\n",
    "\n",
    "    def normalize(self, tensors: Tensor[comp_spec]) -> Tensor[comp_spec]:\n",
    "        # W_i -> (W_i / ||W_i||) / coef_i\n",
    "        ...\n",
    "\n",
    "    def dualize(self, tensors: Tensor[comp_spec], scale_with_dual_norm: bool = True) -> Tensor[comp_spec]:\n",
    "        # G -> dualize(G) / coef_i\n",
    "        # OR\n",
    "        # G -> dualize(G) * ||G||^\\dagger / coef_i\n",
    "        ...\n",
    "\n",
    "    def initialize(self) -> Tensor[comp_spec]:\n",
    "        ...\n",
    "```\n",
    "\n",
    "The traits we track for both module and ops are:\n",
    "```py\n",
    "\n",
    "\n",
    "class ModulaOpInterface:\n",
    "    # mass, the amount of feature learning a single application of this op gives\n",
    "    mass: float\n",
    "    # sensitivity\n",
    "    op_norm_bound: float   # this is probably a property, since it depends on tensor norm and bounds\n",
    "\n",
    "\n",
    "class ModuleMeta(ModulaOpInterface):\n",
    "    # mass\n",
    "    mass: float = float(has_param)\n",
    "\n",
    "    param_spec: pytree[TensorMeta]\n",
    "    has_param: bool                 # property (i.e., module vs op)\n",
    "\n",
    "    def state_dict_to_param_dict(self, pytree[Tensor]) -> Tensor[param_spec]:\n",
    "        ...\n",
    "\n",
    "    def param_dict_to_state_dict(self, Tensor[param_spec]) ->  pytree[Tensor]:\n",
    "        ...\n",
    "\n",
    "    scale_flex: bool\n",
    "    scale_inv: bool\n",
    "\n",
    "    def build_out_spec(self, in_spec: pytree[TensorMeta]) -> pytree[TensorMeta]:\n",
    "        # use TensorMeta.to for implicit conversion\n",
    "        pass\n",
    "\n",
    "    # sensitivity\n",
    "    def op_norm_bounds(self, in_spec: pytree[TensorMeta]) -> (float[param_spec])[out_spec]:\n",
    "        # using OpNormMode, generate `b_i` coeffs for each output\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "a comp graph must be consisted entirely with modules & ops that satisfy these. we provide initial ones for the following pytorch module & ops:\n",
    "1. `nn.Linear`\n",
    "2. `nn.LayerNorm`\n",
    "3. `torch.ops.aten.add`\n",
    "3. `torch.ops.aten.relu`\n",
    "4. `torch.ops.aten.gelu`\n",
    "\n",
    "based on above, we can compute the following on each node of the graph `res := op(*args)`, which is a tensor, using also modula concat rules:\n",
    "(the key is to consider the module from overall input -> here)\n",
    "```py\n",
    "class NodeMeta(ModulaOpInterface):\n",
    "    # mass\n",
    "    mass: float = float(has_param)\n",
    "    # sensitivity\n",
    "    op_norm_bound: float   # property\n",
    "\n",
    "    module: ModuleMeta\n",
    "    args: pytree[NodeMeta]  # yep, traced nodes only have args\n",
    "\n",
    "    in_spec: pytree[TensorMeta] = map(lambda arg: arg.out_spec, args)\n",
    "    out_spec: pytree[TensorMeta] = module.build_out_spec(in_spec)\n",
    "\n",
    "    def build_cat_arg_coeffs\n",
    "\n",
    "res._cat_arg_mass:                    float                  := sum(arg.mass for arg in args)                                          # mass of the op from input -> (args),    defn 4.b\n",
    "res._cat_arg_op_norm_bound:           float                  := sum(arg.op_norm_bound for arg in args)                                # op norm of the op from input -> (args), defn 4.c\n",
    "res._cat_arg_op_norm_weight:          float[op.in_spec]      := op.in_spec.unflatten([res.cat_arg_mass / arg.mass for arg in args])    # coeffs in ||_M from input -> args,      defn 4.d\n",
    "\n",
    "res.out_spec = op.out_spec\n",
    "res.norm:                            float[op.out_spec]     := map(lambda x: x * res.cat_arg_op_norm_bound, op.op_norm_bound)         # norm of each output\n",
    "res.mass:                            float                  := res.cat_arg_mass + op.mass                                             # mass of the op from input -> here,      defn 3.b\n",
    "res.op_norm_bound:                   float                  := res.cat_op_norm_bound * op.op_norm_bound                               # op norm of the op from input -> here,   defn 3.c\n",
    "res.op_norm_weight:                  float[dict(in=op.in_spec, param=op.param_spec)]\n",
    "                                                            := [[[input]]]   (res.mass / arg.mass) * res.cat_arg_op_norm_weight[arg] * op.op_norm_bound                       # defn 3.d\n",
    "                                                            := [[[param]]]   (res.mass /  op.mass) * op.op_norm_weight[param]                                                 # defn 3.d\n",
    "```\n",
    "then we can backfill\n",
    "```py\n",
    "op.param_spec[param].norm_scale\n",
    "```\n",
    "\n",
    "The goal is to, after given a module, reason about norms and assign `op_norm` so\n",
    "1. each intermediate & output result is well-normed, assuming input rms=1\n",
    "\n",
    "\n",
    "```\n",
    "[[ Note ]] Feature learning and mass\n",
    "the current definition of M.mass is agnostic to lip, which is weird.\n",
    "\n",
    "model(x) := g(x) + f(x) * 1e-10 vs model(x) := g(x) * 1e-10 + f(x)\n",
    "\n",
    "both f has the same mass, which is supposedly \"the amount of feature learning done by f\", yet f in the latter matters way more. Intuitively, these gs and fs should not have the same amount of feature learning, but they share the same .mass.\n",
    "\n",
    "Looking at prop 3 (feature learning is apportioned by mass), we can see that the scaling in RHS with M.norm(\\Delta w). To achieve equal effect on output, each module should have M_k.mass = 1/s_k so that unit change in \\Delta w could lead to unit change in Y.\n",
    "\n",
    "So it feels more intuitive to say that M_k.mass * s_k is the amount of feature learning done by M_k.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([299.0000, 298.0000, 297.0000, 296.0000, 295.0000, 294.0000, 293.0000,\n",
       "        292.0000, 291.0000, 290.0000, 289.0000, 288.0000, 287.0000, 286.0000,\n",
       "        285.0000, 284.0000, 283.0000, 282.0000, 281.0000, 280.0000, 279.0000,\n",
       "        278.0000, 277.0000, 276.0000, 275.0000, 274.0000, 273.0000, 272.0000,\n",
       "        271.0000, 270.0000, 269.0000, 268.0000, 267.0000, 266.0000, 265.0000,\n",
       "        264.0000, 263.0000, 262.0000, 261.0000, 260.0000, 259.0000, 258.0000,\n",
       "        257.0000, 256.0000, 255.0000, 254.0000, 253.0000, 252.0000, 251.0000,\n",
       "        250.0000, 249.0000, 248.0000, 247.0000, 246.0000, 245.0000, 244.0000,\n",
       "        243.0000, 242.0000, 241.0000, 240.0000, 239.0000, 238.0000, 237.0000,\n",
       "        236.0000, 235.0000, 234.0000, 233.0000, 232.0000, 231.0000, 230.0000,\n",
       "        229.0000, 228.0000, 227.0000, 226.0000, 225.0000, 224.0000, 223.0000,\n",
       "        222.0000, 221.0000, 220.0000, 219.0000, 218.0000, 217.0000, 216.0000,\n",
       "        215.0000, 214.0000, 213.0000, 212.0000, 211.0000, 210.0000, 209.0000,\n",
       "        208.0000, 207.0000, 206.0000, 205.0000, 204.0000, 203.0000, 202.0000,\n",
       "        201.0000, 200.0000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 100\n",
    "rhos = [0.5/L]\n",
    "for _ in range(L - 1):\n",
    "    rhos.insert(0, rhos[0] / (1 + rhos[0]))\n",
    "rhos = torch.tensor(rhos)\n",
    "\n",
    "plt.plot(rhos)\n",
    "plt.show()\n",
    "1/rhos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050, 0.0050,\n",
       "        0.0050])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining = (1 + rhos.flip(0)).cumprod(dim=0).flip(0)\n",
    "remaining = torch.cat([remaining[1:], torch.ones_like(remaining[0:1])])\n",
    "remaining * rhos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhos[-1] / rhos[0] * (1 + rhos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Worked out example:\n",
    "```py\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.affine = nn.Linear(12, 12)\n",
    "        self.res = nn.Sequential(\n",
    "            nn.Linear(12, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, 12)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.affine(x) + self.affine(self.res(x))\n",
    "```\n",
    "\n",
    "We first dynamo export it as a graph module as following (simplified)\n",
    "```py\n",
    "def forward(self, x):\n",
    "    x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
    "    fn864993__affine__linear = torch.ops.modula.fn864993__affine__Linear.default(x)\n",
    "    fn864993__res_0__linear = torch.ops.modula.fn864993__res_0__Linear.default(x);  x = None\n",
    "    relu = torch.ops.aten.relu.default(fn864993__res_0__linear);  fn864993__res_0__linear = None\n",
    "    fn864993__res_2__linear = torch.ops.modula.fn864993__res_2__Linear.default(relu);  relu = None\n",
    "    relu_1 = torch.ops.aten.relu.default(fn864993__res_2__linear);  fn864993__res_2__linear = None\n",
    "    fn864993__res_4__layer_norm = torch.ops.mopdula.fn864993__res_4__layer_norm.default(relu_1);  relu_1 = None\n",
    "    fn864993__res_5__linear = torch.ops.modula.fn864993__res_5__Linear.default(fn864993__res_4__layer_norm);  layer_norm = None\n",
    "    fn864993__affine__linear_1 = torch.ops.modula.fn864993__affine__Linear.default(fn864993__res_5__linear);  fn864993__res_5__linear = None\n",
    "    add_39 = torch.ops.aten.add.Tensor(fn864993__affine__linear, fn864993__affine__linear_1);  fn864993__affine__linear = fn864993__affine__linear_1 = None\n",
    "    return pytree.tree_unflatten((add_39,), self._out_spec)\n",
    "```\n",
    "where\n",
    "```yaml\n",
    "torch.ops.modula.fn864993__affine__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1\n",
    "torch.ops.modula.fn864993__res_0__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1\n",
    "torch.ops.modula.fn864993__res_2__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1\n",
    "torch.ops.modula.fn864993__res_4__layer_norm:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: True\n",
    "    mass: 1\n",
    "    op_norm: 1 \n",
    "torch.ops.modula.fn864993__res_5__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1 \n",
    "torch.ops.aten.relu.default:\n",
    "    ...\n",
    "    scale_flex: False\n",
    "    scale_inv: False\n",
    "    mass: 0\n",
    "    op_norm: 1\n",
    "torch.ops.aten.add.Tensor:\n",
    "    ...\n",
    "    scale_flex: False\n",
    "    scale_inv: False\n",
    "    mass: 0\n",
    "    op_norm: 1\n",
    "```\n",
    "\n",
    "then we can compute for each node\n",
    "```yaml\n",
    "x:\n",
    "    mass: 0\n",
    "    rms_norm: 1\n",
    "fn864993__affine__linear:\n",
    "    mass: 1  # 0 + 1\n",
    "    rms_norm: 1\n",
    "fn864993__res_0__linear:\n",
    "    mass: 1\n",
    "    rms_norm: 1\n",
    "relu:\n",
    "    mass: 1  # 1 + 0\n",
    "    rms_norm: 1\n",
    "fn864993__res_2__linear:\n",
    "    mass: 2  # 1 + 0 + 1\n",
    "    rms_norm: 1\n",
    "relu_1:\n",
    "    mass: 2  # 1 + 0 + 1 + 0\n",
    "    rms_norm: 1\n",
    "fn864993__res_4__layer_norm:\n",
    "    mass: 3  # 1 + 0 + 1 + 0 + 1\n",
    "    rms_norm: 1\n",
    "fn864993__res_5__linear:\n",
    "    mass: 4  # 1 + 0 + 1 + 0 + 1 + 1\n",
    "    rms_norm: 1\n",
    "fn864993__affine__linear_1:\n",
    "    mass: 5  # 1 + 0 + 1 + 0 + 1 + 1 + 1\n",
    "    rms_norm: 1\n",
    "# concat(fn864993__affine__linear, fn864993__affine__linear_1)\n",
    "#     mass: 6  # 1 + 5\n",
    "#     rms_norm: (1, 1)\n",
    "add_39:\n",
    "    mass: 6\n",
    "    rms_norm: 2  # 1 + 1\n",
    "```\n",
    "and for each module\n",
    "```yaml\n",
    "torch.ops.modula.fn864993__affine__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1\n",
    "torch.ops.modula.fn864993__res_0__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1\n",
    "torch.ops.modula.fn864993__res_2__Linear:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: False\n",
    "    mass: 1\n",
    "    op_norm: 1\n",
    "torch.ops.modula.fn864993__res_4__layer_norm:\n",
    "    ...\n",
    "    scale_flex: True\n",
    "    scale_inv: True\n",
    "    mass: 1\n",
    "    op_norm: 1 \n",
    "torch.ops.modula.fn864993__res_5__Linear:\n",
    "    overall_mass_fraction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torch.library.custom_op to define a new custom operator.\n",
    "# If your operator mutates any input Tensors, their names must be specified\n",
    "# in the ``mutates_args`` argument.\n",
    "import abc\n",
    "import torch.nn.modules.module\n",
    "from torch.export import export, Dim\n",
    "from torch.export.exported_program import ExportedProgram, InputKind, OutputKind\n",
    "import uuid\n",
    "import torch._dynamo\n",
    "from torch._functorch.aot_autograd import aot_module, aot_module_simplified\n",
    "from torch._dynamo.backends.common import aot_autograd\n",
    "from functorch.compile import make_boxed_func\n",
    "from torch._decomp import core_aten_decompositions\n",
    "from torch._dynamo.backends.inductor import inductor\n",
    "from torch._subclasses.fake_tensor import FakeTensorMode\n",
    "from torch._guards import detect_fake_mode, active_fake_mode\n",
    "from typing import *\n",
    "import inspect\n",
    "\n",
    "ModuleType = TypeVar('ModuleType', bound=nn.Module)\n",
    "\n",
    "class ModuleSpec(Generic[ModuleType], metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def make_opaque_op(self, module_uuid: str, submodule_path: str, submodule: ModuleType) -> Callable:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_opaque_op(module_uuid: str, submodule_path: str, submodule: nn.Module):\n",
    "\n",
    "    def extended_forward(*inp_param_buf):\n",
    "        return submodule.forward(*inp_param_buf[:-(len(params) + len(buffers))])\n",
    "\n",
    "    forward_sig = inspect.signature(submodule.forward)\n",
    "    added_sig_params = OrderedDict(forward_sig.parameters)\n",
    "\n",
    "    params = dict(submodule.named_parameters())\n",
    "    buffers = dict(submodule.named_buffers())\n",
    "    for k in sorted(params.keys()):\n",
    "        added_sig_params[k] = inspect.Parameter(name=k, kind=inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=torch.Tensor)\n",
    "    for k in sorted(buffers.keys()):\n",
    "        added_sig_params[k] = inspect.Parameter(name=k, kind=inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=torch.Tensor)\n",
    "    extended_forward.__signature__ = forward_sig.replace(parameters=added_sig_params.values())\n",
    "\n",
    "    cop = torch.library.custom_op(\n",
    "        f\"modula::fn{module_uuid}__{submodule_path.replace('.', '_')}__{submodule.__class__.__name__}\",\n",
    "        extended_forward,\n",
    "        mutates_args=(),\n",
    "    )\n",
    "\n",
    "    # Use register_fake to add a ``FakeTensor`` kernel for the operator\n",
    "    cop.register_fake(extended_forward)\n",
    "    # @cop.register_fake\n",
    "    # def _(input: torch.Tensor):\n",
    "    #     fake_mode: FakeTensorMode = active_fake_mode()\n",
    "    #     print(fake_mode.allow_non_fake_inputs)\n",
    "    #     return submodule.forward(input)\n",
    "\n",
    "    return cop\n",
    "    cop = torch.library.custom_op(\n",
    "        f\"modula::fn{module_uuid}__{submodule_path.replace('.', '_')}__{submodule.__class__.__name__}\",\n",
    "        submodule.forward,  # TODO: should we respect hooks?\n",
    "        mutates_args=(),\n",
    "    )\n",
    "\n",
    "    # Use register_fake to add a ``FakeTensor`` kernel for the operator\n",
    "    cop.register_fake(submodule.forward)\n",
    "    # @cop.register_fake\n",
    "    # def _(input: torch.Tensor):\n",
    "    #     fake_mode: FakeTensorMode = active_fake_mode()\n",
    "    #     print(fake_mode.allow_non_fake_inputs)\n",
    "    #     return submodule.forward(input)\n",
    "    return cop\n",
    "\n",
    "\n",
    "def make_scalarized_op(module_uuid: str, submodule_path: str, submodule: nn.Module, scalarized: Callable[[nn.Module], Any]):\n",
    "    cop = torch.library.custom_op(\n",
    "        f\"modula::fn{module_uuid}__{submodule_path.replace('.', '_')}__{submodule.__class__.__name__}\",\n",
    "        submodule.forward,  # TODO: should we respect hooks?\n",
    "        mutates_args=(),\n",
    "    )\n",
    "\n",
    "    # Use register_fake to add a ``FakeTensor`` kernel for the operator\n",
    "    # cop.register_fake(submodule.forward)\n",
    "    return cop\n",
    "\n",
    "MODULE_TO_MAKE_OPAQUE_OPS = {\n",
    "    nn.Linear: make_opaque_op,\n",
    "}\n",
    "\n",
    "def make_module_opaque_ops(module: nn.Module):\n",
    "    # get a 6 digit hex uuid\n",
    "    module_uuid = str(uuid.uuid4())[:6]\n",
    "    opaque_ops = {}\n",
    "    for name, submodule in module.named_modules():\n",
    "        module_cls = type(submodule)\n",
    "        if module_cls in MODULE_TO_MAKE_OPAQUE_OPS:  # test exact type match, not just subclass\n",
    "            opaque_ops[submodule] = MODULE_TO_MAKE_OPAQUE_OPS[module_cls](module_uuid, name, submodule)\n",
    "    return opaque_ops\n",
    "\n",
    "\n",
    "def compile_module(module: nn.Module, example_args, example_kwargs, dynamic_shapes=None) -> torch.fx.GraphModule:\n",
    "    opaque_ops = make_module_opaque_ops(module)\n",
    "    forward_hooks = {}\n",
    "\n",
    "    def add_hooks(module: nn.Module):\n",
    "        should_replace_with_opaque_op = True\n",
    "\n",
    "        def forward_hook(module, args, kwargs, output):\n",
    "            nonlocal should_replace_with_opaque_op\n",
    "            if should_replace_with_opaque_op:\n",
    "                try:\n",
    "                    should_replace_with_opaque_op = False\n",
    "\n",
    "                    params = dict(module.named_parameters())\n",
    "                    buffers = dict(module.named_buffers())\n",
    "\n",
    "                    output = opaque_ops[module](*args, **kwargs, **params, **buffers)  # use the opaque op\n",
    "                finally:\n",
    "                    should_replace_with_opaque_op = True\n",
    "            return output\n",
    "\n",
    "        return module.register_forward_hook(forward_hook, with_kwargs=True)\n",
    "\n",
    "    for submodule in opaque_ops.keys():\n",
    "        forward_hooks[submodule] = add_hooks(submodule)\n",
    "    try:\n",
    "        # torch._dynamo.reset()\n",
    "        # gm, guards = torch._dynamo.export(module, aten_graph=True)(*example_args, **example_kwargs)\n",
    "        # # print(gm)\n",
    "        # # print(gm._in_spec)\n",
    "        # # print(guards)\n",
    "        # # print(torch.fx.symbolic_trace(module))\n",
    "        # return gm\n",
    "        # print('---')\n",
    "\n",
    "        # Specify that the first dimension of each input is that batch size\n",
    "        ep = export(module, example_args, example_kwargs, dynamic_shapes=dynamic_shapes)\n",
    "\n",
    "        ep.run_decompositions()\n",
    "        # print(ep.graph)\n",
    "        # print(ep.module())\n",
    "\n",
    "        return ep.module()\n",
    "\n",
    "        # def my_backend(gm, sample_inputs):\n",
    "        #     def my_compiler(gm, sample_inputs):\n",
    "        #         # <implement your compiler here>\n",
    "        #         print(\"Decomposed fx Graph in Aten IR:\")\n",
    "        #         gm.print_readable()\n",
    "        #         # from torch._inductor.compile_fx import compile_fx\n",
    "        #         # gm = compile_fx(gm, sample_inputs)\n",
    "        #         return make_boxed_func(gm)\n",
    "\n",
    "        #     gm.print_readable()\n",
    "        #     print('---')\n",
    "        #     return gm\n",
    "        #     # Invoke AOTAutograd\n",
    "        #     return aot_module_simplified(\n",
    "        #         gm,\n",
    "        #         sample_inputs,\n",
    "        #         fw_compiler=my_compiler,\n",
    "        #     )\n",
    "\n",
    "        # fn = torch.compile(module, backend=my_backend)\n",
    "        # # triggers compilation of forward graph on the first run\n",
    "        # out = fn(torch.randn(2, 10).requires_grad_())\n",
    "\n",
    "        # triggers compilation of backward graph on the first run\n",
    "        # out.sum().backward()\n",
    "    finally:\n",
    "        for hook in forward_hooks.values():\n",
    "            hook.remove()\n",
    "        for op in opaque_ops.values():\n",
    "            op._lib._destroy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WWrapper(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(w)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.w\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.affine = nn.Linear(12, 12)\n",
    "        self.w = WWrapper(torch.randn(12, 12))\n",
    "        self.res = nn.Sequential(\n",
    "            nn.Linear(12, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256, 12)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x, self.w.w)\n",
    "        usv = self.affine.weight.svd()\n",
    "        u = usv.U\n",
    "        s = usv.S\n",
    "        print(x.shape)\n",
    "        v = usv.V\n",
    "        b = 3.14\n",
    "        u = (u + b).clamp_(min=0)\n",
    "        return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\n",
    "\n",
    "net = MyNet()\n",
    "\n",
    "batch = Dim(\"batch\")\n",
    "example_args, example_kwargs = (torch.randn(2, 12),), {}\n",
    "dynamic_shapes = ({0: batch},)\n",
    "\n",
    "gm = compile_module(net, example_args, example_kwargs, dynamic_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeSpec(tuple, None, [TreeSpec(tuple, None, [*]),\n",
       "  TreeSpec(dict, [], [])])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm._in_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils._pytree.tree_structure(list(gm.graph.nodes)[11].meta['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': <torch.fx.graph.Graph at 0x329530890>,\n",
       " 'name': 'w_w',\n",
       " 'op': 'get_attr',\n",
       " 'target': 'w.w',\n",
       " '_input_nodes': {},\n",
       " '_args': (),\n",
       " '_kwargs': {},\n",
       " 'users': {matmul: None},\n",
       " 'type': None,\n",
       " '_sort_key': (8, 0),\n",
       " '_repr_fn': None,\n",
       " 'meta': {'val': Parameter(FakeTensor(..., size=(12, 12), requires_grad=True)),\n",
       "  'tensor_meta': TensorMetadata(shape=torch.Size([12, 12]), dtype=torch.float32, requires_grad=True, stride=(12, 1), memory_format=torch.contiguous_format, is_quantized=False, qparams={}),\n",
       "  'from_node': [('matmul', <function _operator.matmul(a, b, /)>)],\n",
       "  'seq_nr': 1568,\n",
       "  'example_value': Parameter(FakeTensor(..., size=(12, 12), requires_grad=True)),\n",
       "  'source_fn_stack': [('matmul', <function _operator.matmul(a, b, /)>)]}}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(list(gm.graph.nodes)[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': <torch.fx.graph.Graph at 0x329530890>,\n",
       " 'name': 'res_4_weight',\n",
       " 'op': 'get_attr',\n",
       " 'target': 'res.4.weight',\n",
       " '_input_nodes': {},\n",
       " '_args': (),\n",
       " '_kwargs': {},\n",
       " 'users': {layer_norm: None},\n",
       " 'type': None,\n",
       " '_sort_key': (9, 0),\n",
       " '_repr_fn': None,\n",
       " 'meta': {'val': FakeTensor(..., size=(256,), requires_grad=True),\n",
       "  'tensor_meta': TensorMetadata(shape=torch.Size([256]), dtype=torch.float32, requires_grad=True, stride=(1,), memory_format=torch.contiguous_format, is_quantized=False, qparams={}),\n",
       "  'source_fn_stack': [('l__self___res_4',\n",
       "    torch.nn.modules.normalization.LayerNorm)],\n",
       "  'from_node': [('l__self___res_4', 'L__self___res_4')],\n",
       "  'seq_nr': 1568,\n",
       "  'example_value': FakeTensor(..., size=(s0, 256), grad_fn=<NativeLayerNormBackward0>)}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(list(gm.graph.nodes)[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name                        target                                   args                                                   kwargs\n",
      "-------------  --------------------------  ---------------------------------------  -----------------------------------------------------  --------\n",
      "get_attr       w_w                         w.w                                      ()                                                     {}\n",
      "get_attr       affine_weight               affine.weight                            ()                                                     {}\n",
      "get_attr       affine_bias                 affine.bias                              ()                                                     {}\n",
      "get_attr       res_0_weight                res.0.weight                             ()                                                     {}\n",
      "get_attr       res_0_bias                  res.0.bias                               ()                                                     {}\n",
      "get_attr       res_2_weight                res.2.weight                             ()                                                     {}\n",
      "get_attr       res_2_bias                  res.2.bias                               ()                                                     {}\n",
      "get_attr       res_5_weight                res.5.weight                             ()                                                     {}\n",
      "get_attr       res_5_bias                  res.5.bias                               ()                                                     {}\n",
      "get_attr       res_4_weight                res.4.weight                             ()                                                     {}\n",
      "get_attr       res_4_bias                  res.4.bias                               ()                                                     {}\n",
      "placeholder    x                           x                                        ()                                                     {}\n",
      "call_function  svd                         aten.svd.default                         (affine_weight,)                                       {}\n",
      "call_function  getitem                     <built-in function getitem>              (svd, 0)                                               {}\n",
      "call_function  getitem_1                   <built-in function getitem>              (svd, 1)                                               {}\n",
      "call_function  add                         aten.add.Tensor                          (getitem, 3.14)                                        {}\n",
      "call_function  clamp                       aten.clamp.default                       (add, 0)                                               {}\n",
      "call_function  fn4d1dd5__affine__linear    modula.fn4d1dd5__affine__Linear.default  (x, affine_bias, affine_weight)                        {}\n",
      "call_function  fn4d1dd5__res_0__linear     modula.fn4d1dd5__res_0__Linear.default   (x, res_0_bias, res_0_weight)                          {}\n",
      "call_function  relu                        aten.relu.default                        (fn4d1dd5__res_0__linear,)                             {}\n",
      "call_function  fn4d1dd5__res_2__linear     modula.fn4d1dd5__res_2__Linear.default   (relu, res_2_bias, res_2_weight)                       {}\n",
      "call_function  relu_1                      aten.relu.default                        (fn4d1dd5__res_2__linear,)                             {}\n",
      "call_function  layer_norm                  aten.layer_norm.default                  (relu_1, [256], res_4_weight, res_4_bias)              {}\n",
      "call_function  fn4d1dd5__res_5__linear     modula.fn4d1dd5__res_5__Linear.default   (layer_norm, res_5_bias, res_5_weight)                 {}\n",
      "call_function  fn4d1dd5__affine__linear_1  modula.fn4d1dd5__affine__Linear.default  (fn4d1dd5__res_5__linear, affine_bias, affine_weight)  {}\n",
      "call_function  matmul                      aten.matmul.default                      (fn4d1dd5__affine__linear_1, w_w)                      {}\n",
      "call_function  add_43                      aten.add.Tensor                          (fn4d1dd5__affine__linear, matmul)                     {}\n",
      "call_function  sum_1                       aten.sum.default                         (clamp,)                                               {}\n",
      "call_function  add_47                      aten.add.Tensor                          (add_43, sum_1)                                        {}\n",
      "call_function  sum_2                       aten.sum.default                         (getitem_1,)                                           {}\n",
      "call_function  add_51                      aten.add.Tensor                          (add_47, sum_2)                                        {}\n",
      "output         output_1                    output                                   ((add_51,),)                                           {}\n"
     ]
    }
   ],
   "source": [
    "gm.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FakeTensor(..., size=(s0, 12))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gm.graph.nodes)[17].meta['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, x):\n",
      "        x: \"f32[s0, 12]\"; \n",
      "    \n",
      "        x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "        # No stacktrace found for following nodes\n",
      "        w_w: \"f32[12, 12]\" = self.w.w\n",
      "        affine_weight: \"f32[12, 12]\" = self.affine.weight\n",
      "        affine_bias: \"f32[12]\" = self.affine.bias;  affine_bias = None\n",
      "        res_0_weight: \"f32[256, 12]\" = getattr(self.res, \"0\").weight;  res_0_weight = None\n",
      "        res_0_bias: \"f32[256]\" = getattr(self.res, \"0\").bias;  res_0_bias = None\n",
      "        res_2_weight: \"f32[256, 256]\" = getattr(self.res, \"2\").weight;  res_2_weight = None\n",
      "        res_2_bias: \"f32[256]\" = getattr(self.res, \"2\").bias;  res_2_bias = None\n",
      "        res_5_weight: \"f32[12, 256]\" = getattr(self.res, \"5\").weight;  res_5_weight = None\n",
      "        res_5_bias: \"f32[12]\" = getattr(self.res, \"5\").bias;  res_5_bias = None\n",
      "        res_4_weight: \"f32[256]\" = getattr(self.res, \"4\").weight\n",
      "        res_4_bias: \"f32[256]\" = getattr(self.res, \"4\").bias\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:25 in forward, code: usv = self.affine.weight.svd()\n",
      "        svd = torch.ops.aten.svd.default(affine_weight);  affine_weight = None\n",
      "        getitem: \"f32[12, 12]\" = svd[0]\n",
      "        getitem_1: \"f32[12]\" = svd[1];  svd = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:31 in forward, code: u = (u + b).clamp_(min=0)\n",
      "        add: \"f32[12, 12]\" = torch.ops.aten.add.Tensor(getitem, 3.14);  getitem = None\n",
      "        clamp: \"f32[12, 12]\" = torch.ops.aten.clamp.default(add, 0);  add = None\n",
      "        \n",
      "         # File: /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669 in __call__, code: return self._opoverload(*args, **kwargs)\n",
      "        fn13a35c__affine__linear: \"f32[s0, 12]\" = torch.ops.modula.fn13a35c__affine__Linear.default(x)\n",
      "        fn13a35c__res_0__linear: \"f32[s0, 256]\" = torch.ops.modula.fn13a35c__res_0__Linear.default(x);  x = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:32 in forward, code: return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\n",
      "        relu: \"f32[s0, 256]\" = torch.ops.aten.relu.default(fn13a35c__res_0__linear);  fn13a35c__res_0__linear = None\n",
      "        \n",
      "         # File: /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669 in __call__, code: return self._opoverload(*args, **kwargs)\n",
      "        fn13a35c__res_2__linear: \"f32[s0, 256]\" = torch.ops.modula.fn13a35c__res_2__Linear.default(relu);  relu = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:32 in forward, code: return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\n",
      "        relu_1: \"f32[s0, 256]\" = torch.ops.aten.relu.default(fn13a35c__res_2__linear);  fn13a35c__res_2__linear = None\n",
      "        layer_norm: \"f32[s0, 256]\" = torch.ops.aten.layer_norm.default(relu_1, [256], res_4_weight, res_4_bias);  relu_1 = res_4_weight = res_4_bias = None\n",
      "        \n",
      "         # File: /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669 in __call__, code: return self._opoverload(*args, **kwargs)\n",
      "        fn13a35c__res_5__linear: \"f32[s0, 12]\" = torch.ops.modula.fn13a35c__res_5__Linear.default(layer_norm);  layer_norm = None\n",
      "        fn13a35c__affine__linear_1: \"f32[s0, 12]\" = torch.ops.modula.fn13a35c__affine__Linear.default(fn13a35c__res_5__linear);  fn13a35c__res_5__linear = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:7 in forward, code: return x @ self.w\n",
      "        matmul: \"f32[s0, 12]\" = torch.ops.aten.matmul.default(fn13a35c__affine__linear_1, w_w);  fn13a35c__affine__linear_1 = w_w = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:32 in forward, code: return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\n",
      "        add_43: \"f32[s0, 12]\" = torch.ops.aten.add.Tensor(fn13a35c__affine__linear, matmul);  fn13a35c__affine__linear = matmul = None\n",
      "        sum_1: \"f32[]\" = torch.ops.aten.sum.default(clamp);  clamp = None\n",
      "        add_47: \"f32[s0, 12]\" = torch.ops.aten.add.Tensor(add_43, sum_1);  add_43 = sum_1 = None\n",
      "        sum_2: \"f32[]\" = torch.ops.aten.sum.default(getitem_1);  getitem_1 = None\n",
      "        add_51: \"f32[s0, 12]\" = torch.ops.aten.add.Tensor(add_47, sum_2);  add_47 = sum_2 = None\n",
      "        return pytree.tree_unflatten((add_51,), self._out_spec)\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'class GraphModule(torch.nn.Module):\\n    def forward(self, x):\\n        x: \"f32[s0, 12]\"; \\n    \\n        x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\\n        # No stacktrace found for following nodes\\n        w_w: \"f32[12, 12]\" = self.w.w\\n        affine_weight: \"f32[12, 12]\" = self.affine.weight\\n        affine_bias: \"f32[12]\" = self.affine.bias;  affine_bias = None\\n        res_0_weight: \"f32[256, 12]\" = getattr(self.res, \"0\").weight;  res_0_weight = None\\n        res_0_bias: \"f32[256]\" = getattr(self.res, \"0\").bias;  res_0_bias = None\\n        res_2_weight: \"f32[256, 256]\" = getattr(self.res, \"2\").weight;  res_2_weight = None\\n        res_2_bias: \"f32[256]\" = getattr(self.res, \"2\").bias;  res_2_bias = None\\n        res_5_weight: \"f32[12, 256]\" = getattr(self.res, \"5\").weight;  res_5_weight = None\\n        res_5_bias: \"f32[12]\" = getattr(self.res, \"5\").bias;  res_5_bias = None\\n        res_4_weight: \"f32[256]\" = getattr(self.res, \"4\").weight\\n        res_4_bias: \"f32[256]\" = getattr(self.res, \"4\").bias\\n        \\n         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:25 in forward, code: usv = self.affine.weight.svd()\\n        svd = torch.ops.aten.svd.default(affine_weight);  affine_weight = None\\n        getitem: \"f32[12, 12]\" = svd[0]\\n        getitem_1: \"f32[12]\" = svd[1];  svd = None\\n        \\n         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:31 in forward, code: u = (u + b).clamp_(min=0)\\n        add: \"f32[12, 12]\" = torch.ops.aten.add.Tensor(getitem, 3.14);  getitem = None\\n        clamp: \"f32[12, 12]\" = torch.ops.aten.clamp.default(add, 0);  add = None\\n        \\n         # File: /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669 in __call__, code: return self._opoverload(*args, **kwargs)\\n        fn13a35c__affine__linear: \"f32[s0, 12]\" = torch.ops.modula.fn13a35c__affine__Linear.default(x)\\n        fn13a35c__res_0__linear: \"f32[s0, 256]\" = torch.ops.modula.fn13a35c__res_0__Linear.default(x);  x = None\\n        \\n         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:32 in forward, code: return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\\n        relu: \"f32[s0, 256]\" = torch.ops.aten.relu.default(fn13a35c__res_0__linear);  fn13a35c__res_0__linear = None\\n        \\n         # File: /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669 in __call__, code: return self._opoverload(*args, **kwargs)\\n        fn13a35c__res_2__linear: \"f32[s0, 256]\" = torch.ops.modula.fn13a35c__res_2__Linear.default(relu);  relu = None\\n        \\n         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:32 in forward, code: return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\\n        relu_1: \"f32[s0, 256]\" = torch.ops.aten.relu.default(fn13a35c__res_2__linear);  fn13a35c__res_2__linear = None\\n        layer_norm: \"f32[s0, 256]\" = torch.ops.aten.layer_norm.default(relu_1, [256], res_4_weight, res_4_bias);  relu_1 = res_4_weight = res_4_bias = None\\n        \\n         # File: /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_library/custom_ops.py:669 in __call__, code: return self._opoverload(*args, **kwargs)\\n        fn13a35c__res_5__linear: \"f32[s0, 12]\" = torch.ops.modula.fn13a35c__res_5__Linear.default(layer_norm);  layer_norm = None\\n        fn13a35c__affine__linear_1: \"f32[s0, 12]\" = torch.ops.modula.fn13a35c__affine__Linear.default(fn13a35c__res_5__linear);  fn13a35c__res_5__linear = None\\n        \\n         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:7 in forward, code: return x @ self.w\\n        matmul: \"f32[s0, 12]\" = torch.ops.aten.matmul.default(fn13a35c__affine__linear_1, w_w);  fn13a35c__affine__linear_1 = w_w = None\\n        \\n         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_18954/3682757950.py:32 in forward, code: return self.affine(input=x) + self.w(self.affine(self.res(x)))  + u.sum() + s.sum()\\n        add_43: \"f32[s0, 12]\" = torch.ops.aten.add.Tensor(fn13a35c__affine__linear, matmul);  fn13a35c__affine__linear = matmul = None\\n        sum_1: \"f32[]\" = torch.ops.aten.sum.default(clamp);  clamp = None\\n        add_47: \"f32[s0, 12]\" = torch.ops.aten.add.Tensor(add_43, sum_1);  add_43 = sum_1 = None\\n        sum_2: \"f32[]\" = torch.ops.aten.sum.default(getitem_1);  getitem_1 = None\\n        add_51: \"f32[s0, 12]\" = torch.ops.aten.add.Tensor(add_47, sum_2);  add_47 = sum_2 = None\\n        return pytree.tree_unflatten((add_51,), self._out_spec)\\n        '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.print_readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1] failed while attempting to run meta for aten.mm.default\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1] Traceback (most recent call last):\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]   File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 2013, in _dispatch_impl\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]     r = func(*args, **kwargs)\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]   File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_ops.py\", line 716, in __call__\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]     return self._op(*args, **kwargs)\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]   File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_prims_common/wrappers.py\", line 273, in _fn\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]     result = fn(*args, **kwargs)\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]              ^^^^^^^^^^^^^^^^^^^\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]   File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_meta_registrations.py\", line 2100, in meta_mm\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]     torch._check(\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]   File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/__init__.py\", line 1565, in _check\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]     _check_with(RuntimeError, cond, message)\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]   File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/__init__.py\", line 1547, in _check_with\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1]     raise error_type(message_evaluated)\n",
      "E1028 16:35:34.942000 85121 site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0_1] RuntimeError: a and b must have same reduction dim, but got [s0, s1] X [12, 12].\n",
      "[W1028 16:35:35.327631000 PyInterpreter.cpp:264] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\n",
      "[W1028 16:35:35.327653000 PyInterpreter.cpp:264] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\n",
      "[W1028 16:35:35.330578000 PyInterpreter.cpp:264] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\n",
      "[W1028 16:35:35.330594000 PyInterpreter.cpp:264] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\n"
     ]
    },
    {
     "ename": "TorchRuntimeError",
     "evalue": "Failed running call_function <built-in function linear>(*(FakeTensor(..., size=(s0, s1)), Parameter(FakeTensor(..., size=(12, 12), requires_grad=True)), Parameter(FakeTensor(..., size=(12,), requires_grad=True))), **{}):\na and b must have same reduction dim, but got [s0, s1] X [12, 12].\n\nfrom user code:\n   File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_85121/3895323117.py\", line 16, in forward\n    return self.affine(x) + self.affine(self.res(x))  + u.sum() + v.sum()\n  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1841, in _call_impl\n    return inner()\n  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1790, in inner\n    result = forward_call(*args, **kwargs)\n  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTorchRuntimeError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m example_args, example_kwargs \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m),), {}\n\u001b[1;32m      3\u001b[0m dynamic_shapes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;241m0\u001b[39m: batch}}\n\u001b[0;32m----> 5\u001b[0m compile_module(MyNet(), example_args, example_kwargs, dynamic_shapes)\n",
      "Cell \u001b[0;32mIn[104], line 83\u001b[0m, in \u001b[0;36mcompile_module\u001b[0;34m(module, example_args, example_kwargs, dynamic_shapes)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m---> 83\u001b[0m     gm, guards \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mexport(module, aten_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\u001b[38;5;241m*\u001b[39mexample_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample_kwargs)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(gm)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(gm\u001b[38;5;241m.\u001b[39m_in_spec)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:1432\u001b[0m, in \u001b[0;36mexport.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1432\u001b[0m     result_traced \u001b[38;5;241m=\u001b[39m opt_f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConstraintViolationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1434\u001b[0m     constraint_violation_error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:465\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    461\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    469\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    470\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1269\u001b[0m, in \u001b[0;36mCatchErrorsWrapper.__call__\u001b[0;34m(self, frame, cache_entry, frame_state)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[1;32m   1264\u001b[0m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks, frame_state\n\u001b[1;32m   1265\u001b[0m             )\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[0;32m-> 1269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torchdynamo_orig_callable(\n\u001b[1;32m   1270\u001b[0m         frame, cache_entry, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks, frame_state, skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1271\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:526\u001b[0m, in \u001b[0;36mConvertFrameAssert.__call__\u001b[0;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    510\u001b[0m compile_id \u001b[38;5;241m=\u001b[39m CompileId(frame_id, frame_compile_id)\n\u001b[1;32m    512\u001b[0m signpost_event(\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_frame_assert._compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m     },\n\u001b[1;32m    524\u001b[0m )\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _compile(\n\u001b[1;32m    527\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_code,\n\u001b[1;32m    528\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_globals,\n\u001b[1;32m    529\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_locals,\n\u001b[1;32m    530\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_builtins,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torchdynamo_orig_callable,\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_one_graph,\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export,\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_constraints,\n\u001b[1;32m    535\u001b[0m     hooks,\n\u001b[1;32m    536\u001b[0m     cache_entry,\n\u001b[1;32m    537\u001b[0m     cache_size,\n\u001b[1;32m    538\u001b[0m     frame,\n\u001b[1;32m    539\u001b[0m     frame_state\u001b[38;5;241m=\u001b[39mframe_state,\n\u001b[1;32m    540\u001b[0m     compile_id\u001b[38;5;241m=\u001b[39mcompile_id,\n\u001b[1;32m    541\u001b[0m     skip\u001b[38;5;241m=\u001b[39mskip \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    542\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:924\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[0m\n\u001b[1;32m    922\u001b[0m guarded_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 924\u001b[0m     guarded_code \u001b[38;5;241m=\u001b[39m compile_inner(code, one_graph, hooks, transform)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:666\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_compile.compile_inner\u001b[39m\u001b[38;5;124m\"\u001b[39m, phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentire_frame_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m CompileTimeInstructionCounter\u001b[38;5;241m.\u001b[39mrecord():\n\u001b[0;32m--> 666\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _compile_inner(code, one_graph, hooks, transform)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py:87\u001b[0m, in \u001b[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39mprofile_compile_time(\n\u001b[1;32m     90\u001b[0m     function, phase_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:699\u001b[0m, in \u001b[0;36m_compile.<locals>._compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    697\u001b[0m CompileContext\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mattempt \u001b[38;5;241m=\u001b[39m attempt\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 699\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m transform_code_object(code, transform)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mRestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py:1322\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m   1319\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m   1320\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m-> 1322\u001b[0m transformations(instructions, code_options)\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:219\u001b[0m, in \u001b[0;36mpreserve_global_state.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m exit_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m    216\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39m_symbolic_trace\u001b[38;5;241m.\u001b[39m_maybe_revert_all_patches()\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:634\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context), tracer\u001b[38;5;241m.\u001b[39mset_current_tx():\n\u001b[0;32m--> 634\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnspecializeRestartAnalysis:\n\u001b[1;32m    636\u001b[0m     speculation_log\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2796\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2796\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep():\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_table[inst\u001b[38;5;241m.\u001b[39mopcode](\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_fn(\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_context_manager_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.CALL\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inst)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[0m, in \u001b[0;36mInstructionTranslatorBase._call\u001b[0;34m(self, inst, call_kw)\u001b[0m\n\u001b[1;32m   2268\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2271\u001b[0m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_function(fn, args, kwargs)\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.call_function\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(fn\u001b[38;5;241m.\u001b[39mcall_function(\u001b[38;5;28mself\u001b[39m, args, kwargs))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/nn_module.py:899\u001b[0m, in \u001b[0;36mUnspecializedNNModuleVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    892\u001b[0m     record_nn_module_stack(\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(mod)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_nn_module_stack_source(), tx, mod\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m--> 899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mUserFunctionVariable(fn, source\u001b[38;5;241m=\u001b[39msource)\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    900\u001b[0m         tx, [\u001b[38;5;28mself\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(args), kwargs\n\u001b[1;32m    901\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:324\u001b[0m, in \u001b[0;36mUserFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constant:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invoke_and_store_as_constant(\n\u001b[1;32m    321\u001b[0m         tx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name(), args, kwargs\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcall_function(tx, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:111\u001b[0m, in \u001b[0;36mBaseUserFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_function\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    107\u001b[0m     tx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructionTranslator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     args: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList[VariableTracker]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     kwargs: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDict[str, VariableTracker]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariableTracker\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tx\u001b[38;5;241m.\u001b[39minline_user_function_return(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_args(), \u001b[38;5;241m*\u001b[39margs], kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:836\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.inline_user_function_return\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minline_user_function_return\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m    A call to some user defined function by inlining it.\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InliningInstructionTranslator\u001b[38;5;241m.\u001b[39minline_call(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001b[0m, in \u001b[0;36mInliningInstructionTranslator.inline_call\u001b[0;34m(cls, parent, func, args, kwargs)\u001b[0m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minline_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m, parent, func, args, kwargs):\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch\u001b[38;5;241m.\u001b[39mdict(counters, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munimplemented\u001b[39m\u001b[38;5;124m\"\u001b[39m: counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minline_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]}):\n\u001b[0;32m-> 3011\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39minline_call_(parent, func, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001b[0m, in \u001b[0;36mInliningInstructionTranslator.inline_call_\u001b[0;34m(parent, func, args, kwargs)\u001b[0m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[0;32m-> 3139\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3141\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep():\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_table[inst\u001b[38;5;241m.\u001b[39mopcode](\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_fn(\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_context_manager_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.CALL\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inst)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[0m, in \u001b[0;36mInstructionTranslatorBase._call\u001b[0;34m(self, inst, call_kw)\u001b[0m\n\u001b[1;32m   2268\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2271\u001b[0m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_function(fn, args, kwargs)\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.call_function\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(fn\u001b[38;5;241m.\u001b[39mcall_function(\u001b[38;5;28mself\u001b[39m, args, kwargs))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:111\u001b[0m, in \u001b[0;36mBaseUserFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_function\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    107\u001b[0m     tx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructionTranslator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     args: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList[VariableTracker]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     kwargs: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDict[str, VariableTracker]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariableTracker\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tx\u001b[38;5;241m.\u001b[39minline_user_function_return(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_args(), \u001b[38;5;241m*\u001b[39margs], kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:836\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.inline_user_function_return\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minline_user_function_return\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m    A call to some user defined function by inlining it.\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InliningInstructionTranslator\u001b[38;5;241m.\u001b[39minline_call(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001b[0m, in \u001b[0;36mInliningInstructionTranslator.inline_call\u001b[0;34m(cls, parent, func, args, kwargs)\u001b[0m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minline_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m, parent, func, args, kwargs):\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch\u001b[38;5;241m.\u001b[39mdict(counters, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munimplemented\u001b[39m\u001b[38;5;124m\"\u001b[39m: counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minline_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]}):\n\u001b[0;32m-> 3011\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39minline_call_(parent, func, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001b[0m, in \u001b[0;36mInliningInstructionTranslator.inline_call_\u001b[0;34m(parent, func, args, kwargs)\u001b[0m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[0;32m-> 3139\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3141\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep():\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_table[inst\u001b[38;5;241m.\u001b[39mopcode](\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_fn(\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_context_manager_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:1680\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.CALL_FUNCTION_EX\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;66;03m# Map to a dictionary of str -> VariableTracker\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m kwargsvars \u001b[38;5;241m=\u001b[39m kwargsvars\u001b[38;5;241m.\u001b[39mkeys_as_python_constant()\n\u001b[0;32m-> 1680\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_function(fn, argsvars\u001b[38;5;241m.\u001b[39mitems, kwargsvars)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.call_function\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(fn\u001b[38;5;241m.\u001b[39mcall_function(\u001b[38;5;28mself\u001b[39m, args, kwargs))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:385\u001b[0m, in \u001b[0;36mUserMethodVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invoke_and_store_as_constant(tx, fn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name(), args, kwargs)\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcall_function(tx, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:324\u001b[0m, in \u001b[0;36mUserFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constant:\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invoke_and_store_as_constant(\n\u001b[1;32m    321\u001b[0m         tx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name(), args, kwargs\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcall_function(tx, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:111\u001b[0m, in \u001b[0;36mBaseUserFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_function\u001b[39m(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    107\u001b[0m     tx: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructionTranslator\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     args: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList[VariableTracker]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     kwargs: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDict[str, VariableTracker]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariableTracker\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tx\u001b[38;5;241m.\u001b[39minline_user_function_return(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_args(), \u001b[38;5;241m*\u001b[39margs], kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:836\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.inline_user_function_return\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minline_user_function_return\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m    A call to some user defined function by inlining it.\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InliningInstructionTranslator\u001b[38;5;241m.\u001b[39minline_call(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001b[0m, in \u001b[0;36mInliningInstructionTranslator.inline_call\u001b[0;34m(cls, parent, func, args, kwargs)\u001b[0m\n\u001b[1;32m   3008\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minline_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m, parent, func, args, kwargs):\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch\u001b[38;5;241m.\u001b[39mdict(counters, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munimplemented\u001b[39m\u001b[38;5;124m\"\u001b[39m: counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minline_call\u001b[39m\u001b[38;5;124m\"\u001b[39m]}):\n\u001b[0;32m-> 3011\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39minline_call_(parent, func, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001b[0m, in \u001b[0;36mInliningInstructionTranslator.inline_call_\u001b[0;34m(parent, func, args, kwargs)\u001b[0m\n\u001b[1;32m   3137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   3138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[0;32m-> 3139\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   3140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3141\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep():\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_table[inst\u001b[38;5;241m.\u001b[39mopcode](\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_fn(\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_context_manager_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.CALL\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inst)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[0m, in \u001b[0;36mInstructionTranslatorBase._call\u001b[0;34m(self, inst, call_kw)\u001b[0m\n\u001b[1;32m   2268\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2271\u001b[0m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_function(fn, args, kwargs)\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.call_function\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(fn\u001b[38;5;241m.\u001b[39mcall_function(\u001b[38;5;28mself\u001b[39m, args, kwargs))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/torch.py:897\u001b[0m, in \u001b[0;36mTorchInGraphFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m], variables\u001b[38;5;241m.\u001b[39mTensorVariable):\n\u001b[1;32m    889\u001b[0m                 \u001b[38;5;66;03m# Calling fake tensor propagation can mutate the out= tensor in\u001b[39;00m\n\u001b[1;32m    890\u001b[0m                 \u001b[38;5;66;03m# tx.output.tracked_fakes. tracked_fakes are used to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[38;5;66;03m# guards. So save the shape now, and check later if it has\u001b[39;00m\n\u001b[1;32m    894\u001b[0m                 \u001b[38;5;66;03m# changed. If it has, graph break.\u001b[39;00m\n\u001b[1;32m    895\u001b[0m                 fake_out_shape \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 897\u001b[0m             tensor_variable \u001b[38;5;241m=\u001b[39m wrap_fx_proxy(\n\u001b[1;32m    898\u001b[0m                 tx\u001b[38;5;241m=\u001b[39mtx,\n\u001b[1;32m    899\u001b[0m                 proxy\u001b[38;5;241m=\u001b[39mtx\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mcreate_proxy(\n\u001b[1;32m    900\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    901\u001b[0m                     fn_,\n\u001b[1;32m    902\u001b[0m                     \u001b[38;5;241m*\u001b[39mproxy_args_kwargs(args, kwargs),\n\u001b[1;32m    903\u001b[0m                 ),\n\u001b[1;32m    904\u001b[0m             )\n\u001b[1;32m    906\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    907\u001b[0m                 \u001b[38;5;28misinstance\u001b[39m(tensor_variable, TensorVariable)\n\u001b[1;32m    908\u001b[0m                 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m    909\u001b[0m                 \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mas_python_constant()\n\u001b[1;32m    910\u001b[0m             ):\n\u001b[1;32m    911\u001b[0m                 unimplemented(\n\u001b[1;32m    912\u001b[0m \u001b[38;5;250m                    \u001b[39m\u001b[38;5;124;03m\"\"\"factory functions that return tensors that require grad are not supported.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03mEither create the tensor outside the compiled region, or do not set the tensor to require_grad\"\"\"\u001b[39;00m\n\u001b[1;32m    914\u001b[0m                 )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/builder.py:2037\u001b[0m, in \u001b[0;36mwrap_fx_proxy\u001b[0;34m(tx, proxy, example_value, subclass_type, **options)\u001b[0m\n\u001b[1;32m   2029\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2030\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtx\u001b[39m\u001b[38;5;124m\"\u001b[39m: tx,\n\u001b[1;32m   2031\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxy\u001b[39m\u001b[38;5;124m\"\u001b[39m: proxy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions,\n\u001b[1;32m   2035\u001b[0m }\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subclass_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap_fx_proxy_cls(target_cls\u001b[38;5;241m=\u001b[39mTensorVariable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2039\u001b[0m     result \u001b[38;5;241m=\u001b[39m wrap_fx_proxy_cls(target_cls\u001b[38;5;241m=\u001b[39mTensorWithTFOverrideVariable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/builder.py:2124\u001b[0m, in \u001b[0;36mwrap_fx_proxy_cls\u001b[0;34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_disable_saved_tensors_hooks_during_tracing():\n\u001b[1;32m   2120\u001b[0m     \u001b[38;5;66;03m# with preserve_rng_state():\u001b[39;00m\n\u001b[1;32m   2121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2122\u001b[0m         \u001b[38;5;66;03m# only allow_non_graph_fake in this instance because we handle the non-fake\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m         \u001b[38;5;66;03m# cases properly below.\u001b[39;00m\n\u001b[0;32m-> 2124\u001b[0m         example_value \u001b[38;5;241m=\u001b[39m get_fake_value(proxy\u001b[38;5;241m.\u001b[39mnode, tx, allow_non_graph_fake\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2126\u001b[0m     \u001b[38;5;66;03m# Handle recursive calls here\u001b[39;00m\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m maybe_get_fake_mode(example_value) \u001b[38;5;129;01mis\u001b[39;00m tx\u001b[38;5;241m.\u001b[39mfake_mode:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:2082\u001b[0m, in \u001b[0;36mget_fake_value\u001b[0;34m(node, tx, allow_non_graph_fake)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cause, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(cause):\n\u001b[1;32m   2080\u001b[0m         unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTypeError \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcause\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2082\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TorchRuntimeError(\u001b[38;5;28mstr\u001b[39m(e))\u001b[38;5;241m.\u001b[39mwith_traceback(e\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_non_graph_fake:\n\u001b[1;32m   2085\u001b[0m     _ \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_map_only(\n\u001b[1;32m   2086\u001b[0m         torch\u001b[38;5;241m.\u001b[39mTensor, functools\u001b[38;5;241m.\u001b[39mpartial(ensure_graph_fake, tx\u001b[38;5;241m=\u001b[39mtx), ret_val\n\u001b[1;32m   2087\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:2017\u001b[0m, in \u001b[0;36mget_fake_value\u001b[0;34m(node, tx, allow_non_graph_fake)\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2016\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tx\u001b[38;5;241m.\u001b[39mfake_mode, enable_python_dispatcher():\n\u001b[0;32m-> 2017\u001b[0m         ret_val \u001b[38;5;241m=\u001b[39m wrap_fake_exception(\n\u001b[1;32m   2018\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m: run_node(tx\u001b[38;5;241m.\u001b[39moutput, node, args, kwargs, nnmodule)\n\u001b[1;32m   2019\u001b[0m         )\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:1574\u001b[0m, in \u001b[0;36mwrap_fake_exception\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_fake_exception\u001b[39m(fn):\n\u001b[1;32m   1573\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn()\n\u001b[1;32m   1575\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m UnsupportedFakeTensorException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1576\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unimplemented\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:2018\u001b[0m, in \u001b[0;36mget_fake_value.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2016\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tx\u001b[38;5;241m.\u001b[39mfake_mode, enable_python_dispatcher():\n\u001b[1;32m   2017\u001b[0m         ret_val \u001b[38;5;241m=\u001b[39m wrap_fake_exception(\n\u001b[0;32m-> 2018\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m: run_node(tx\u001b[38;5;241m.\u001b[39moutput, node, args, kwargs, nnmodule)\n\u001b[1;32m   2019\u001b[0m         )\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:2150\u001b[0m, in \u001b[0;36mrun_node\u001b[0;34m(tracer, node, args, kwargs, nnmodule)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         unimplemented(make_error_message(e), from_exc\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(make_error_message(e))\u001b[38;5;241m.\u001b[39mwith_traceback(\n\u001b[1;32m   2151\u001b[0m             e\u001b[38;5;241m.\u001b[39m__traceback__\n\u001b[1;32m   2152\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(op)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py:2132\u001b[0m, in \u001b[0;36mrun_node\u001b[0;34m(tracer, node, args, kwargs, nnmodule)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_function\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mtarget(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2133\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m op \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall_method\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], node\u001b[38;5;241m.\u001b[39mtarget)(\u001b[38;5;241m*\u001b[39margs[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py:21\u001b[0m, in \u001b[0;36mcount.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1238\u001b[0m, in \u001b[0;36mFakeTensorMode.__torch_dispatch__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   1235\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_dispatch_mode(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TorchDispatchModeKey\u001b[38;5;241m.\u001b[39mFAKE) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m ), func\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(func, types, args, kwargs)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1240\u001b[0m     log\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake tensor raised TypeError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1692\u001b[0m, in \u001b[0;36mFakeTensorMode.dispatch\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_enabled:\n\u001b[0;32m-> 1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_dispatch_impl(func, types, args, kwargs)\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_impl(func, types, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1348\u001b[0m, in \u001b[0;36mFakeTensorMode._cached_dispatch_impl\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     FakeTensorMode\u001b[38;5;241m.\u001b[39mcache_bypasses[e\u001b[38;5;241m.\u001b[39mreason] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m _UNASSIGNED:\n\u001b[0;32m-> 1348\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_impl(func, types, args, kwargs)\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1943\u001b[0m, in \u001b[0;36mFakeTensorMode._dispatch_impl\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m decomposition_table \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1934\u001b[0m     has_symbolic_sizes\n\u001b[1;32m   1935\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1940\u001b[0m     )\n\u001b[1;32m   1941\u001b[0m ):\n\u001b[1;32m   1942\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m-> 1943\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m decomposition_table[func](\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1945\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# Decomposes CompositeImplicitAutograd ops\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     r \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mdecompose(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_prims_common/wrappers.py:273\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, is_out\u001b[38;5;241m=\u001b[39m(out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_names)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_decomp/decompositions.py:83\u001b[0m, in \u001b[0;36mtype_casts.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 83\u001b[0m r \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;241m*\u001b[39mtree_map(increase_prec, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtree_map(increase_prec, kwargs))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_dtype_only:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_decomp/decompositions.py:1515\u001b[0m, in \u001b[0;36maddmm\u001b[0;34m(self, mat1, mat2, beta, alpha)\u001b[0m\n\u001b[1;32m   1513\u001b[0m     beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(beta)\n\u001b[1;32m   1514\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(alpha)\n\u001b[0;32m-> 1515\u001b[0m out \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(mat1, mat2)\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py:21\u001b[0m, in \u001b[0;36mcount.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m=\u001b[39m simple_call_counter[fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1238\u001b[0m, in \u001b[0;36mFakeTensorMode.__torch_dispatch__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m   1235\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_dispatch_mode(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TorchDispatchModeKey\u001b[38;5;241m.\u001b[39mFAKE) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1236\u001b[0m ), func\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(func, types, args, kwargs)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1240\u001b[0m     log\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfake tensor raised TypeError\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1692\u001b[0m, in \u001b[0;36mFakeTensorMode.dispatch\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_enabled:\n\u001b[0;32m-> 1692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_dispatch_impl(func, types, args, kwargs)\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_impl(func, types, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:1348\u001b[0m, in \u001b[0;36mFakeTensorMode._cached_dispatch_impl\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     FakeTensorMode\u001b[38;5;241m.\u001b[39mcache_bypasses[e\u001b[38;5;241m.\u001b[39mreason] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m _UNASSIGNED:\n\u001b[0;32m-> 1348\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_impl(func, types, args, kwargs)\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py:2013\u001b[0m, in \u001b[0;36mFakeTensorMode._dispatch_impl\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2012\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m in_kernel_invocation_manager(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2013\u001b[0m         r \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2014\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m not_implemented_error:\n\u001b[1;32m   2015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m maybe_run_unsafe_fallback(not_implemented_error)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_ops.py:716\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 716\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_prims_common/wrappers.py:273\u001b[0m, in \u001b[0;36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[0;34m(out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, is_out\u001b[38;5;241m=\u001b[39m(out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_names)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_meta_registrations.py:2100\u001b[0m, in \u001b[0;36mmeta_mm\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   2098\u001b[0m N, M1 \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2099\u001b[0m M2, P \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m-> 2100\u001b[0m torch\u001b[38;5;241m.\u001b[39m_check(\n\u001b[1;32m   2101\u001b[0m     M1 \u001b[38;5;241m==\u001b[39m M2,\n\u001b[1;32m   2102\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma and b must have same reduction dim, but got [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] X [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mM2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mP\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2103\u001b[0m )\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\u001b[38;5;241m.\u001b[39mnew_empty(N, P)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/__init__.py:1565\u001b[0m, in \u001b[0;36m_check\u001b[0;34m(cond, message)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check\u001b[39m(cond, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Throws error containing an optional message if the specified condition\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;124;03m    is False.\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;124;03m            message. Default: ``None``\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1565\u001b[0m     _check_with(\u001b[38;5;167;01mRuntimeError\u001b[39;00m, cond, message)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/__init__.py:1547\u001b[0m, in \u001b[0;36m_check_with\u001b[0;34m(error_type, cond, message)\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage must be a callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1545\u001b[0m     message_evaluated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(message())\n\u001b[0;32m-> 1547\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error_type(message_evaluated)\n",
      "\u001b[0;31mTorchRuntimeError\u001b[0m: Failed running call_function <built-in function linear>(*(FakeTensor(..., size=(s0, s1)), Parameter(FakeTensor(..., size=(12, 12), requires_grad=True)), Parameter(FakeTensor(..., size=(12,), requires_grad=True))), **{}):\na and b must have same reduction dim, but got [s0, s1] X [12, 12].\n\nfrom user code:\n   File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_85121/3895323117.py\", line 16, in forward\n    return self.affine(x) + self.affine(self.res(x))  + u.sum() + v.sum()\n  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1841, in _call_impl\n    return inner()\n  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1790, in inner\n    result = forward_call(*args, **kwargs)\n  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n"
     ]
    }
   ],
   "source": [
    "batch = Dim(\"batch\")\n",
    "example_args, example_kwargs = (torch.randn(2, 10),), {}\n",
    "dynamic_shapes = {\"x\": {0: batch}}\n",
    "\n",
    "compile_module(MyNet(), example_args, example_kwargs, dynamic_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_x_: \"f32[10]\"):\n",
      "        l_x_ = L_x_\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:16 in forward, code: x = x + x.abs()\n",
      "        abs_1: \"f32[10]\" = l_x_.abs()\n",
      "        x: \"f32[10]\" = l_x_ + abs_1;  l_x_ = abs_1 = None\n",
      "        return (x,)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: \"f32[10]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:16 in forward, code: x = x + x.abs()\n",
      "        abs_1: \"f32[10]\" = torch.ops.aten.abs.default(primals_1)\n",
      "        add: \"f32[10]\" = torch.ops.aten.add.Tensor(primals_1, abs_1);  abs_1 = None\n",
      "        return (add, primals_1)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_: \"f32[20]\", L_self_parameters_w1_: \"f32[20, 10]\", L_self_parameters_w2_: \"f32[10, 20]\"):\n",
      "        l_stack0_ = L_stack0_\n",
      "        l_self_parameters_w1_ = L_self_parameters_w1_\n",
      "        l_self_parameters_w2_ = L_self_parameters_w2_\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:18 in torch_dynamo_resume_in_forward_at_17, code: x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
      "        gelu: \"f32[10, 20]\" = torch._C._nn.gelu(l_self_parameters_w2_);  l_self_parameters_w2_ = None\n",
      "        matmul: \"f32[20, 20]\" = l_self_parameters_w1_ @ gelu;  gelu = None\n",
      "        tanh: \"f32[20, 20]\" = matmul.tanh();  matmul = None\n",
      "        x: \"f32[20]\" = l_stack0_ @ tanh;  l_stack0_ = tanh = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:19 in torch_dynamo_resume_in_forward_at_17, code: y = self.w1.pow(2)\n",
      "        y: \"f32[20, 10]\" = l_self_parameters_w1_.pow(2);  l_self_parameters_w1_ = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_17, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        log_softmax: \"f32[20]\" = torch.nn.functional.log_softmax(x, dim = -1)\n",
      "        getitem: \"f32[10]\" = x[(Ellipsis, slice(None, 10, None))];  x = None\n",
      "        return (log_softmax, getitem, y)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: \"f32[20]\", primals_2: \"f32[20, 10]\", primals_3: \"f32[10, 20]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:18 in torch_dynamo_resume_in_forward_at_17, code: x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
      "        gelu: \"f32[10, 20]\" = torch.ops.aten.gelu.default(primals_3)\n",
      "        mm: \"f32[20, 20]\" = torch.ops.aten.mm.default(primals_2, gelu)\n",
      "        tanh: \"f32[20, 20]\" = torch.ops.aten.tanh.default(mm);  mm = None\n",
      "        unsqueeze: \"f32[1, 20]\" = torch.ops.aten.unsqueeze.default(primals_1, 0);  primals_1 = None\n",
      "        mm_1: \"f32[1, 20]\" = torch.ops.aten.mm.default(unsqueeze, tanh)\n",
      "        squeeze: \"f32[20]\" = torch.ops.aten.squeeze.dims(mm_1, [0]);  mm_1 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:19 in torch_dynamo_resume_in_forward_at_17, code: y = self.w1.pow(2)\n",
      "        pow_1: \"f32[20, 10]\" = torch.ops.aten.pow.Tensor_Scalar(primals_2, 2)\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_17, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        _log_softmax: \"f32[20]\" = torch.ops.aten._log_softmax.default(squeeze, -1, False)\n",
      "        slice_1: \"f32[10]\" = torch.ops.aten.slice.Tensor(squeeze, 0, 0, 10);  squeeze = None\n",
      "        return (_log_softmax, slice_1, pow_1, primals_2, primals_3, gelu, tanh, unsqueeze, _log_softmax)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack1_: \"f32[20]\", L_stack0_: \"f32[20]\", L_y_: \"f32[20, 10]\"):\n",
      "        l_stack1_ = L_stack1_\n",
      "        l_stack0_ = L_stack0_\n",
      "        l_y_ = L_y_\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_20, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        mean: \"f32[]\" = l_stack1_.mean();  l_stack1_ = None\n",
      "        mul: \"f32[20]\" = l_stack0_ * mean;  l_stack0_ = mean = None\n",
      "        mean_1: \"f32[]\" = l_y_.mean();  l_y_ = None\n",
      "        x: \"f32[20]\" = mul - mean_1;  mul = mean_1 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:21 in torch_dynamo_resume_in_forward_at_20, code: return self.fc(x[..., :10].abs()).mean()\n",
      "        getitem: \"f32[10]\" = x[(Ellipsis, slice(None, 10, None))];  x = None\n",
      "        abs_1: \"f32[10]\" = getitem.abs();  getitem = None\n",
      "        return (abs_1,)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: \"f32[20]\", primals_2: \"f32[20]\", primals_3: \"f32[20, 10]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_20, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        mean: \"f32[]\" = torch.ops.aten.mean.default(primals_1);  primals_1 = None\n",
      "        mul: \"f32[20]\" = torch.ops.aten.mul.Tensor(primals_2, mean)\n",
      "        mean_1: \"f32[]\" = torch.ops.aten.mean.default(primals_3);  primals_3 = None\n",
      "        sub: \"f32[20]\" = torch.ops.aten.sub.Tensor(mul, mean_1);  mul = mean_1 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:21 in torch_dynamo_resume_in_forward_at_20, code: return self.fc(x[..., :10].abs()).mean()\n",
      "        slice_1: \"f32[10]\" = torch.ops.aten.slice.Tensor(sub, 0, 0, 10);  sub = None\n",
      "        abs_1: \"f32[10]\" = torch.ops.aten.abs.default(slice_1)\n",
      "        return (abs_1, primals_2, mean, slice_1)\n",
      "        \n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_stack0_: \"f32[20]\"):\n",
      "        l_stack0_ = L_stack0_\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:21 in torch_dynamo_resume_in_forward_at_21, code: return self.fc(x[..., :10].abs()).mean()\n",
      "        mean: \"f32[]\" = l_stack0_.mean();  l_stack0_ = None\n",
      "        return (mean,)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: \"f32[20]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:21 in torch_dynamo_resume_in_forward_at_21, code: return self.fc(x[..., :10].abs()).mean()\n",
      "        mean: \"f32[]\" = torch.ops.aten.mean.default(primals_1);  primals_1 = None\n",
      "        return (mean,)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, tangents_1: \"f32[]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:21 in torch_dynamo_resume_in_forward_at_21, code: return self.fc(x[..., :10].abs()).mean()\n",
      "        expand: \"f32[20]\" = torch.ops.aten.expand.default(tangents_1, [20]);  tangents_1 = None\n",
      "        div: \"f32[20]\" = torch.ops.aten.div.Scalar(expand, 20);  expand = None\n",
      "        return (div,)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_2: \"f32[20]\", mean: \"f32[]\", slice_1: \"f32[10]\", tangents_1: \"f32[10]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:21 in torch_dynamo_resume_in_forward_at_20, code: return self.fc(x[..., :10].abs()).mean()\n",
      "        sign: \"f32[10]\" = torch.ops.aten.sign.default(slice_1);  slice_1 = None\n",
      "        mul_1: \"f32[10]\" = torch.ops.aten.mul.Tensor(tangents_1, sign);  tangents_1 = sign = None\n",
      "        full: \"f32[20]\" = torch.ops.aten.full.default([20], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n",
      "        slice_scatter: \"f32[20]\" = torch.ops.aten.slice_scatter.default(full, mul_1, 0, 0, 10);  full = mul_1 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_20, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        neg: \"f32[20]\" = torch.ops.aten.neg.default(slice_scatter)\n",
      "        sum_1: \"f32[]\" = torch.ops.aten.sum.dim_IntList(neg, []);  neg = None\n",
      "        expand: \"f32[20, 10]\" = torch.ops.aten.expand.default(sum_1, [20, 10]);  sum_1 = None\n",
      "        div: \"f32[20, 10]\" = torch.ops.aten.div.Scalar(expand, 200);  expand = None\n",
      "        mul_2: \"f32[20]\" = torch.ops.aten.mul.Tensor(slice_scatter, primals_2);  primals_2 = None\n",
      "        mul_3: \"f32[20]\" = torch.ops.aten.mul.Tensor(slice_scatter, mean);  slice_scatter = mean = None\n",
      "        sum_2: \"f32[]\" = torch.ops.aten.sum.dim_IntList(mul_2, []);  mul_2 = None\n",
      "        expand_1: \"f32[20]\" = torch.ops.aten.expand.default(sum_2, [20]);  sum_2 = None\n",
      "        div_1: \"f32[20]\" = torch.ops.aten.div.Scalar(expand_1, 20);  expand_1 = None\n",
      "        return (div_1, mul_3, div)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_2: \"f32[20, 10]\", primals_3: \"f32[10, 20]\", gelu: \"f32[10, 20]\", tanh: \"f32[20, 20]\", unsqueeze: \"f32[1, 20]\", _log_softmax: \"f32[20]\", tangents_1: \"f32[20]\", tangents_2: \"f32[10]\", tangents_3: \"f32[20, 10]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:18 in torch_dynamo_resume_in_forward_at_17, code: x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
      "        alias: \"f32[20, 20]\" = torch.ops.aten.alias.default(tanh)\n",
      "        alias_1: \"f32[20, 20]\" = torch.ops.aten.alias.default(alias);  alias = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_17, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        alias_2: \"f32[20]\" = torch.ops.aten.alias.default(_log_softmax);  _log_softmax = None\n",
      "        alias_3: \"f32[20]\" = torch.ops.aten.alias.default(alias_2);  alias_2 = None\n",
      "        full: \"f32[20]\" = torch.ops.aten.full.default([20], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cpu'), pin_memory = False)\n",
      "        slice_scatter: \"f32[20]\" = torch.ops.aten.slice_scatter.default(full, tangents_2, 0, 0, 10);  full = tangents_2 = None\n",
      "        alias_4: \"f32[20]\" = torch.ops.aten.alias.default(alias_3);  alias_3 = None\n",
      "        alias_5: \"f32[20]\" = torch.ops.aten.alias.default(alias_4);  alias_4 = None\n",
      "        exp: \"f32[20]\" = torch.ops.aten.exp.default(alias_5);  alias_5 = None\n",
      "        sum_1: \"f32[1]\" = torch.ops.aten.sum.dim_IntList(tangents_1, [-1], True)\n",
      "        mul: \"f32[20]\" = torch.ops.aten.mul.Tensor(exp, sum_1);  exp = sum_1 = None\n",
      "        sub: \"f32[20]\" = torch.ops.aten.sub.Tensor(tangents_1, mul);  tangents_1 = mul = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:20 in torch_dynamo_resume_in_forward_at_17, code: x = F.log_softmax(x, dim=-1) * self.fc(x[..., :10]).mean() - y.mean()\n",
      "        add: \"f32[20]\" = torch.ops.aten.add.Tensor(slice_scatter, sub);  slice_scatter = sub = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:19 in torch_dynamo_resume_in_forward_at_17, code: y = self.w1.pow(2)\n",
      "        pow_2: \"f32[20, 10]\" = torch.ops.aten.pow.Tensor_Scalar(primals_2, 1.0)\n",
      "        mul_1: \"f32[20, 10]\" = torch.ops.aten.mul.Scalar(pow_2, 2.0);  pow_2 = None\n",
      "        mul_2: \"f32[20, 10]\" = torch.ops.aten.mul.Tensor(tangents_3, mul_1);  tangents_3 = mul_1 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:18 in torch_dynamo_resume_in_forward_at_17, code: x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
      "        unsqueeze_1: \"f32[1, 20]\" = torch.ops.aten.unsqueeze.default(add, 0);  add = None\n",
      "        permute: \"f32[20, 1]\" = torch.ops.aten.permute.default(unsqueeze, [1, 0]);  unsqueeze = None\n",
      "        mm_2: \"f32[20, 20]\" = torch.ops.aten.mm.default(permute, unsqueeze_1);  permute = None\n",
      "        permute_1: \"f32[20, 20]\" = torch.ops.aten.permute.default(tanh, [1, 0]);  tanh = None\n",
      "        mm_3: \"f32[1, 20]\" = torch.ops.aten.mm.default(unsqueeze_1, permute_1);  unsqueeze_1 = permute_1 = None\n",
      "        squeeze_1: \"f32[20]\" = torch.ops.aten.squeeze.dims(mm_3, [0]);  mm_3 = None\n",
      "        alias_6: \"f32[20, 20]\" = torch.ops.aten.alias.default(alias_1);  alias_1 = None\n",
      "        alias_7: \"f32[20, 20]\" = torch.ops.aten.alias.default(alias_6);  alias_6 = None\n",
      "        mul_3: \"f32[20, 20]\" = torch.ops.aten.mul.Tensor(alias_7, alias_7);  alias_7 = None\n",
      "        sub_1: \"f32[20, 20]\" = torch.ops.aten.sub.Tensor(1, mul_3);  mul_3 = None\n",
      "        mul_4: \"f32[20, 20]\" = torch.ops.aten.mul.Tensor(mm_2, sub_1);  mm_2 = sub_1 = None\n",
      "        permute_2: \"f32[10, 20]\" = torch.ops.aten.permute.default(primals_2, [1, 0]);  primals_2 = None\n",
      "        mm_4: \"f32[10, 20]\" = torch.ops.aten.mm.default(permute_2, mul_4);  permute_2 = None\n",
      "        permute_3: \"f32[20, 10]\" = torch.ops.aten.permute.default(gelu, [1, 0]);  gelu = None\n",
      "        mm_5: \"f32[20, 10]\" = torch.ops.aten.mm.default(mul_4, permute_3);  mul_4 = permute_3 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:18 in torch_dynamo_resume_in_forward_at_17, code: x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
      "        add_1: \"f32[20, 10]\" = torch.ops.aten.add.Tensor(mul_2, mm_5);  mul_2 = mm_5 = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:18 in torch_dynamo_resume_in_forward_at_17, code: x = x @ (self.w1 @ F.gelu(self.w2)).tanh()\n",
      "        mul_5: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(primals_3, 0.7071067811865476)\n",
      "        erf: \"f32[10, 20]\" = torch.ops.aten.erf.default(mul_5);  mul_5 = None\n",
      "        add_2: \"f32[10, 20]\" = torch.ops.aten.add.Tensor(erf, 1);  erf = None\n",
      "        mul_6: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(add_2, 0.5);  add_2 = None\n",
      "        mul_7: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(primals_3, primals_3)\n",
      "        mul_8: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(mul_7, -0.5);  mul_7 = None\n",
      "        exp_1: \"f32[10, 20]\" = torch.ops.aten.exp.default(mul_8);  mul_8 = None\n",
      "        mul_9: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(exp_1, 0.3989422804014327);  exp_1 = None\n",
      "        mul_10: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(primals_3, mul_9);  primals_3 = mul_9 = None\n",
      "        add_3: \"f32[10, 20]\" = torch.ops.aten.add.Tensor(mul_6, mul_10);  mul_6 = mul_10 = None\n",
      "        mul_11: \"f32[10, 20]\" = torch.ops.aten.mul.Tensor(mm_4, add_3);  mm_4 = add_3 = None\n",
      "        return (squeeze_1, add_1, mul_11)\n",
      "        \n",
      "Decomposed fx Graph in Aten IR:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: \"f32[10]\", tangents_1: \"f32[10]\"):\n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:16 in forward, code: x = x + x.abs()\n",
      "        sign: \"f32[10]\" = torch.ops.aten.sign.default(primals_1);  primals_1 = None\n",
      "        mul: \"f32[10]\" = torch.ops.aten.mul.Tensor(tangents_1, sign);  sign = None\n",
      "        \n",
      "         # File: /var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1165912469.py:16 in forward, code: x = x + x.abs()\n",
      "        add_1: \"f32[10]\" = torch.ops.aten.add.Tensor(tangents_1, mul);  tangents_1 = mul = None\n",
      "        return (add_1,)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "import torch._dynamo\n",
    "from torch._functorch.aot_autograd import aot_module, aot_module_simplified\n",
    "from torch._dynamo.backends.common import aot_autograd\n",
    "from functorch.compile import make_boxed_func\n",
    "from torch._decomp import core_aten_decompositions\n",
    "from torch._dynamo.backends.inductor import inductor\n",
    "\n",
    "\n",
    "def pattern(x, w):\n",
    "    return x @ w.T\n",
    "    return lerpo_1 + torch.zeros_like(y).sum()\n",
    "    zeros_like = torch.ops.aten.zeros_like.default(x, pin_memory = False)\n",
    "    lerp = torch.ops.aten.lerp.Scalar(x, zeros_like, 0.5)\n",
    "    return lerp\n",
    "\n",
    "pattern = torch.fx.symbolic_trace(nn.Linear.forward).graph\n",
    "\n",
    "def linear_update(x, w):\n",
    "    nout, nin = w.shape\n",
    "    return (x @ w.T) * (nout / nin) ** 0.5\n",
    "    with torch.no_grad():\n",
    "        weight.sub_(1)\n",
    "    return weight @ x\n",
    "\n",
    "def replacement(x, y):\n",
    "    return linear_update(x, y)\n",
    "    return x / 12\n",
    "    return torch.ops.aten.div.Scalar(x, 12)\n",
    "\n",
    "# Backends can further finetune the decompositions if needed\n",
    "# Available decompositions can be found in\n",
    "# torch/_decomp/decompositions.py and torch/_refs/__init__.py\n",
    "decompositions = core_aten_decompositions()\n",
    "decompositions.update(\n",
    "    torch._decomp.get_decompositions([\n",
    "        # torch.ops.aten.addmm,\n",
    "    ])\n",
    ")\n",
    "\n",
    "# def my_compiler(gm, example_inputs):\n",
    "#     gm.print_readable()\n",
    "#     return make_boxed_func(gm.forward)\n",
    "\n",
    "# my_backend = aot_autograd(fw_compiler=my_compiler, decompositions=decompositions)  # bw_compiler=my_compiler\n",
    "\n",
    "def my_backend(gm, sample_inputs):\n",
    "\n",
    "    # gm.print_readable()\n",
    "\n",
    "    # gm = fn = inductor(gm, sample_inputs)\n",
    "\n",
    "    # def get_closure_vars(fn):\n",
    "    #     closure_vars = fn.__code__.co_freevars\n",
    "    #     closure_values = [cell.cell_contents for cell in fn.__closure__]\n",
    "\n",
    "    #     closure_dict = dict(zip(closure_vars, closure_values))\n",
    "    #     return closure_dict\n",
    "    # print(get_closure_vars(get_closure_vars(fn)['fn'])['compiled_fn'])\n",
    "    # gm.print_readable()\n",
    "    # return gm\n",
    "\n",
    "    def my_compiler(gm, sample_inputs):\n",
    "        # <implement your compiler here>\n",
    "        print(\"Decomposed fx Graph in Aten IR:\")\n",
    "        gm.print_readable()\n",
    "        # from torch._inductor.compile_fx import compile_fx\n",
    "        # gm = compile_fx(gm, sample_inputs)\n",
    "        return make_boxed_func(gm)\n",
    "\n",
    "    gm.print_readable()\n",
    "\n",
    "    # Invoke AOTAutograd\n",
    "    return aot_module_simplified(\n",
    "        gm,\n",
    "        sample_inputs,\n",
    "        decompositions=decompositions,\n",
    "        fw_compiler=my_compiler,\n",
    "    )\n",
    "\n",
    "# model_opt = torch.compile(model, backend=my_backend)\n",
    "\n",
    "torch._dynamo.reset()\n",
    "m = MyNet()\n",
    "# gm = torch.fx.symbolic_trace(m)\n",
    "# gm.print_readable()\n",
    "\n",
    "# def match_filter(match, full_graph: fx.Graph, pattern_graph: fx.Graph):\n",
    "#     return is_node_a_parameter(match.placeholder_nodes[1], full_graph)\n",
    "#     pattern_graph.print_tabular()\n",
    "#     full_graph.print_tabular()\n",
    "#     return True\n",
    "\n",
    "# def is_node_a_parameter(node: fx.Node, graph: fx.Graph):\n",
    "#     matches = graph.find_nodes(op='placeholder', target=node.target)  # check reassignment\n",
    "#     if len(matches) == 0:\n",
    "#         # check if node is a parameter\n",
    "#         matches: List[fx.Node] = graph.find_nodes(op='get_attr', target=node.target)\n",
    "#         print(matches[0].target, matches[0].args, matches[0].kwargs)\n",
    "#         if len(matches) == 1:\n",
    "#             return matches[0].target in dict(graph.owning_module.named_parameters()).keys()\n",
    "#         else:\n",
    "#             return False\n",
    "#     else:\n",
    "#         assert len(matches) == 1\n",
    "#         return is_node_a_parameter(matches[0], graph)\n",
    "\n",
    "\n",
    "# matches = subgraph_rewriter.replace_pattern_with_filters(gm, pattern, replacement, match_filters=[match_filter])\n",
    "# gm.print_readable()\n",
    "\n",
    "# fn = torch.compile(backend=my_backend, dynamic=False)(m)\n",
    "fn = torch.compile(m, backend=my_backend)  # now inductor\n",
    "\n",
    "# triggers compilation of forward graph on the first run\n",
    "out = fn(torch.randn(10).requires_grad_())\n",
    "\n",
    "# triggers compilation of backward graph on the first run\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/1196819216.py\", line 1, in <module>\n",
      "    torch.compile(MyNet())(torch.randn(2, 10))\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 465, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/4233013976.py\", line 8, in forward\n",
      "    def forward(self, x):\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1269, in __call__\n",
      "    return self._torchdynamo_orig_callable(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 1064, in __call__\n",
      "    result = self._inner_convert(\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 526, in __call__\n",
      "    return _compile(\n",
      "           ^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 924, in _compile\n",
      "    guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 666, in compile_inner\n",
      "    return _compile_inner(code, one_graph, hooks, transform)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py\", line 87, in wrapper_function\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 699, in _compile_inner\n",
      "    out_code = transform_code_object(code, transform)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "    transformations(instructions, code_options)\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 219, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py\", line 634, in transform\n",
      "    tracer.run()\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2796, in run\n",
      "    super().run()\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 983, in run\n",
      "    while self.step():\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 895, in step\n",
      "    self.dispatch_table[inst.opcode](self, inst)\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 582, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2279, in CALL\n",
      "    self._call(inst)\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 2273, in _call\n",
      "    self.call_function(fn, args, kwargs)\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py\", line 830, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/lazy.py\", line 156, in realize_and_forward\n",
      "    return getattr(self.realize(), name)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/torch.py\", line 897, in call_function\n",
      "    tensor_variable = wrap_fx_proxy(\n",
      "                      ^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/builder.py\", line 2037, in wrap_fx_proxy\n",
      "    return wrap_fx_proxy_cls(target_cls=TensorVariable, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/builder.py\", line 2124, in wrap_fx_proxy_cls\n",
      "    example_value = get_fake_value(proxy.node, tx, allow_non_graph_fake=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 2082, in get_fake_value\n",
      "    raise TorchRuntimeError(str(e)).with_traceback(e.__traceback__) from None\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 2017, in get_fake_value\n",
      "    ret_val = wrap_fake_exception(\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 1574, in wrap_fake_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 2018, in <lambda>\n",
      "    lambda: run_node(tx.output, node, args, kwargs, nnmodule)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 2150, in run_node\n",
      "    raise RuntimeError(make_error_message(e)).with_traceback(\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/utils.py\", line 2132, in run_node\n",
      "    return node.target(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/4233013976.py\", line 16, in <lambda>\n",
      "    fn = lambda x: self.fc(x)\n",
      "                   ^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/utils/_stats.py\", line 21, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1238, in __torch_dispatch__\n",
      "    return self.dispatch(func, types, args, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1692, in dispatch\n",
      "    return self._cached_dispatch_impl(func, types, args, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1348, in _cached_dispatch_impl\n",
      "    output = self._dispatch_impl(func, types, args, kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 1790, in _dispatch_impl\n",
      "    (flat_args, flat_arg_fake_tensors) = self.validate_and_convert_non_fake_tensors(\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 2094, in validate_and_convert_non_fake_tensors\n",
      "    validated_args = [validate(a) for a in flat_args]\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 2094, in <listcomp>\n",
      "    validated_args = [validate(a) for a in flat_args]\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_subclasses/fake_tensor.py\", line 2082, in validate\n",
      "    raise AssertionError(\n",
      "torch._dynamo.exc.TorchRuntimeError: Failed running call_function <function MyNet.forward.<locals>.<lambda> at 0x32c12cb80>(*(FakeTensor(..., size=(2, 10)),), **{}):\n",
      "Please convert all Tensors to FakeTensors first or instantiate FakeTensorMode with 'allow_non_fake_inputs'. Found in aten.t.default(Parameter containing:\n",
      "tensor([...], size=(20, 10), requires_grad=True))\n",
      "\n",
      "from user code:\n",
      "   File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/4233013976.py\", line 19, in torch_dynamo_resume_in_forward_at_17\n",
      "    x = fn(x)\n",
      "\n",
      "Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "\n",
      "\n",
      "You can suppress this exception and fall back to eager by setting:\n",
      "    import torch._dynamo\n",
      "    torch._dynamo.config.suppress_errors = True\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1085, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1182, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/stack_data/core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 78, in collapse_repeated\n",
      "    for is_highlighted, group in itertools.groupby(\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/site-packages/stack_data/utils.py\", line 46, in highlight_unique\n",
      "    counts = Counter(lst)\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/collections/__init__.py\", line 599, in __init__\n",
      "    self.update(iterable, **kwds)\n",
      "  File \"/Users/S_sn/miniconda3/lib/python3.11/collections/__init__.py\", line 690, in update\n",
      "    _count_elements(self, iterable)\n",
      "TypeError: unhashable type: 'dict'\n"
     ]
    }
   ],
   "source": [
    "torch.compile(MyNet())(torch.randn(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unsupported",
     "evalue": "'skip function disable in file /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/decorators.py'\n\nfrom user code:\n   File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/3683954354.py\", line 16, in forward\n    x = torch._dynamo.disable(self.fc)(x)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupported\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Specify that the first dimension of each input is that batch size\u001b[39;00m\n\u001b[1;32m      6\u001b[0m dynamic_shapes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;241m0\u001b[39m: batch}}\n\u001b[0;32m----> 7\u001b[0m ep \u001b[38;5;241m=\u001b[39m export(MyNet(), (torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m),), dynamic_shapes\u001b[38;5;241m=\u001b[39mdynamic_shapes)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/__init__.py:270\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExporting a ScriptModule is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaybe try converting your ScriptModule to an ExportedProgram \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing `TS2EPConverter(mod, args, kwargs).convert()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _export(\n\u001b[1;32m    271\u001b[0m     mod,\n\u001b[1;32m    272\u001b[0m     args,\n\u001b[1;32m    273\u001b[0m     kwargs,\n\u001b[1;32m    274\u001b[0m     dynamic_shapes,\n\u001b[1;32m    275\u001b[0m     strict\u001b[38;5;241m=\u001b[39mstrict,\n\u001b[1;32m    276\u001b[0m     preserve_module_call_signature\u001b[38;5;241m=\u001b[39mpreserve_module_call_signature,\n\u001b[1;32m    277\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    278\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/_trace.py:1017\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m         log_export_usage(\n\u001b[1;32m   1012\u001b[0m             event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport.error.unclassified\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1013\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39merror_type,\n\u001b[1;32m   1014\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m   1015\u001b[0m             flags\u001b[38;5;241m=\u001b[39m_EXPORT_FLAGS,\n\u001b[1;32m   1016\u001b[0m         )\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1019\u001b[0m     _EXPORT_FLAGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/_trace.py:990\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    989\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 990\u001b[0m     ep \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    991\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    992\u001b[0m     log_export_usage(\n\u001b[1;32m    993\u001b[0m         event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport.time\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    994\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mend \u001b[38;5;241m-\u001b[39m start,\n\u001b[1;32m    995\u001b[0m         flags\u001b[38;5;241m=\u001b[39m_EXPORT_FLAGS,\n\u001b[1;32m    996\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mget_ep_stats(ep),\n\u001b[1;32m    997\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/exported_program.py:114\u001b[0m, in \u001b[0;36m_disable_prexisiting_fake_mode.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m unset_fake_temporarily():\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/_trace.py:1880\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, pre_dispatch, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;66;03m# Call the appropriate export function based on the strictness of tracing.\u001b[39;00m\n\u001b[1;32m   1878\u001b[0m export_func \u001b[38;5;241m=\u001b[39m _strict_export \u001b[38;5;28;01mif\u001b[39;00m strict \u001b[38;5;28;01melse\u001b[39;00m _non_strict_export\n\u001b[0;32m-> 1880\u001b[0m export_artifact \u001b[38;5;241m=\u001b[39m export_func(  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   1881\u001b[0m     mod,\n\u001b[1;32m   1882\u001b[0m     args,\n\u001b[1;32m   1883\u001b[0m     kwargs,\n\u001b[1;32m   1884\u001b[0m     dynamic_shapes,\n\u001b[1;32m   1885\u001b[0m     preserve_module_call_signature,\n\u001b[1;32m   1886\u001b[0m     pre_dispatch,\n\u001b[1;32m   1887\u001b[0m     original_state_dict,\n\u001b[1;32m   1888\u001b[0m     original_in_spec,\n\u001b[1;32m   1889\u001b[0m     allow_complex_guards_as_runtime_asserts,\n\u001b[1;32m   1890\u001b[0m     _is_torch_jit_trace,\n\u001b[1;32m   1891\u001b[0m )\n\u001b[1;32m   1892\u001b[0m export_graph_signature: ExportGraphSignature \u001b[38;5;241m=\u001b[39m export_artifact\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msig\n\u001b[1;32m   1894\u001b[0m forward_arg_names \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1895\u001b[0m     _get_forward_arg_names(mod, args, kwargs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_torch_jit_trace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1896\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/_trace.py:1224\u001b[0m, in \u001b[0;36m_strict_export\u001b[0;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, pre_dispatch, original_state_dict, orig_in_spec, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strict_export\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     mod: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m   1213\u001b[0m     args: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     _is_torch_jit_trace: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   1222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExportArtifact:\n\u001b[1;32m   1223\u001b[0m     lower_to_aten \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(_export_to_aten_ir, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _strict_export_lower_to_aten_ir(\n\u001b[1;32m   1225\u001b[0m         mod\u001b[38;5;241m=\u001b[39mmod,\n\u001b[1;32m   1226\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1227\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   1228\u001b[0m         dynamic_shapes\u001b[38;5;241m=\u001b[39mdynamic_shapes,\n\u001b[1;32m   1229\u001b[0m         preserve_module_call_signature\u001b[38;5;241m=\u001b[39mpreserve_module_call_signature,\n\u001b[1;32m   1230\u001b[0m         pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m   1231\u001b[0m         original_state_dict\u001b[38;5;241m=\u001b[39moriginal_state_dict,\n\u001b[1;32m   1232\u001b[0m         orig_in_spec\u001b[38;5;241m=\u001b[39morig_in_spec,\n\u001b[1;32m   1233\u001b[0m         allow_complex_guards_as_runtime_asserts\u001b[38;5;241m=\u001b[39mallow_complex_guards_as_runtime_asserts,\n\u001b[1;32m   1234\u001b[0m         _is_torch_jit_trace\u001b[38;5;241m=\u001b[39m_is_torch_jit_trace,\n\u001b[1;32m   1235\u001b[0m         lower_to_aten_callback\u001b[38;5;241m=\u001b[39mlower_to_aten,\n\u001b[1;32m   1236\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/_trace.py:1252\u001b[0m, in \u001b[0;36m_strict_export_lower_to_aten_ir\u001b[0;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, pre_dispatch, original_state_dict, orig_in_spec, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace, lower_to_aten_callback)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strict_export_lower_to_aten_ir\u001b[39m(\n\u001b[1;32m   1240\u001b[0m     mod: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m   1241\u001b[0m     args: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     lower_to_aten_callback: Callable,\n\u001b[1;32m   1251\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExportArtifact:\n\u001b[0;32m-> 1252\u001b[0m     gm_torch_level \u001b[38;5;241m=\u001b[39m _export_to_torch_ir(\n\u001b[1;32m   1253\u001b[0m         mod,\n\u001b[1;32m   1254\u001b[0m         args,\n\u001b[1;32m   1255\u001b[0m         kwargs,\n\u001b[1;32m   1256\u001b[0m         dynamic_shapes,\n\u001b[1;32m   1257\u001b[0m         preserve_module_call_signature\u001b[38;5;241m=\u001b[39mpreserve_module_call_signature,\n\u001b[1;32m   1258\u001b[0m         restore_fqn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# don't need to restore because we will do it later\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m         allow_complex_guards_as_runtime_asserts\u001b[38;5;241m=\u001b[39mallow_complex_guards_as_runtime_asserts,\n\u001b[1;32m   1260\u001b[0m         _log_export_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1261\u001b[0m     )\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# We detect the fake_mode by looking at gm_torch_level's placeholders, this is the fake_mode created in dynamo.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     (\n\u001b[1;32m   1265\u001b[0m         fake_args,\n\u001b[1;32m   1266\u001b[0m         fake_kwargs,\n\u001b[1;32m   1267\u001b[0m         dynamo_fake_mode,\n\u001b[1;32m   1268\u001b[0m     ) \u001b[38;5;241m=\u001b[39m _extract_fake_inputs(gm_torch_level, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/export/_trace.py:560\u001b[0m, in \u001b[0;36m_export_to_torch_ir\u001b[0;34m(f, args, kwargs, dynamic_shapes, preserve_module_call_signature, disable_constraint_solver, allow_complex_guards_as_runtime_asserts, restore_fqn, _log_export_usage, same_signature)\u001b[0m\n\u001b[1;32m    556\u001b[0m     module_call_specs: Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, pytree\u001b[38;5;241m.\u001b[39mTreeSpec]] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _wrap_submodules(\n\u001b[1;32m    558\u001b[0m         f, preserve_module_call_signature, module_call_specs\n\u001b[1;32m    559\u001b[0m     ), _ignore_backend_decomps():\n\u001b[0;32m--> 560\u001b[0m         gm_torch_level, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mexport(\n\u001b[1;32m    561\u001b[0m             f,\n\u001b[1;32m    562\u001b[0m             dynamic_shapes\u001b[38;5;241m=\u001b[39mtransformed_dynamic_shapes,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    563\u001b[0m             tracing_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbolic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    564\u001b[0m             disable_constraint_solver\u001b[38;5;241m=\u001b[39mdisable_constraint_solver,\n\u001b[1;32m    565\u001b[0m             \u001b[38;5;66;03m# currently the following 2 flags are tied together for export purposes,\u001b[39;00m\n\u001b[1;32m    566\u001b[0m             \u001b[38;5;66;03m# but untangle for sake of dynamo export api\u001b[39;00m\n\u001b[1;32m    567\u001b[0m             prefer_deferred_runtime_asserts_over_guards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    568\u001b[0m             allow_complex_guards_as_runtime_asserts\u001b[38;5;241m=\u001b[39mallow_complex_guards_as_runtime_asserts,\n\u001b[1;32m    569\u001b[0m             _log_export_usage\u001b[38;5;241m=\u001b[39m_log_export_usage,\n\u001b[1;32m    570\u001b[0m             same_signature\u001b[38;5;241m=\u001b[39msame_signature,\n\u001b[1;32m    571\u001b[0m         )(\n\u001b[1;32m    572\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    573\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    574\u001b[0m         )\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ConstraintViolationError, ValueRangeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserError(UserErrorType\u001b[38;5;241m.\u001b[39mCONSTRAINT_VIOLATION, \u001b[38;5;28mstr\u001b[39m(e))  \u001b[38;5;66;03m# noqa: B904\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:1432\u001b[0m, in \u001b[0;36mexport.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# TODO(voz): We may have instances of `f` that mutate inputs, we should track sideeffects and reject.\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1432\u001b[0m     result_traced \u001b[38;5;241m=\u001b[39m opt_f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConstraintViolationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1434\u001b[0m     constraint_violation_error \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:465\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    461\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    462\u001b[0m )\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    469\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    470\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1269\u001b[0m, in \u001b[0;36mCatchErrorsWrapper.__call__\u001b[0;34m(self, frame, cache_entry, frame_state)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[1;32m   1264\u001b[0m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks, frame_state\n\u001b[1;32m   1265\u001b[0m             )\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[0;32m-> 1269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torchdynamo_orig_callable(\n\u001b[1;32m   1270\u001b[0m         frame, cache_entry, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks, frame_state, skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1271\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:526\u001b[0m, in \u001b[0;36mConvertFrameAssert.__call__\u001b[0;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[1;32m    510\u001b[0m compile_id \u001b[38;5;241m=\u001b[39m CompileId(frame_id, frame_compile_id)\n\u001b[1;32m    512\u001b[0m signpost_event(\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_frame_assert._compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m     },\n\u001b[1;32m    524\u001b[0m )\n\u001b[0;32m--> 526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _compile(\n\u001b[1;32m    527\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_code,\n\u001b[1;32m    528\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_globals,\n\u001b[1;32m    529\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_locals,\n\u001b[1;32m    530\u001b[0m     frame\u001b[38;5;241m.\u001b[39mf_builtins,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_torchdynamo_orig_callable,\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_one_graph,\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export,\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_constraints,\n\u001b[1;32m    535\u001b[0m     hooks,\n\u001b[1;32m    536\u001b[0m     cache_entry,\n\u001b[1;32m    537\u001b[0m     cache_size,\n\u001b[1;32m    538\u001b[0m     frame,\n\u001b[1;32m    539\u001b[0m     frame_state\u001b[38;5;241m=\u001b[39mframe_state,\n\u001b[1;32m    540\u001b[0m     compile_id\u001b[38;5;241m=\u001b[39mcompile_id,\n\u001b[1;32m    541\u001b[0m     skip\u001b[38;5;241m=\u001b[39mskip \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    542\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:924\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[0m\n\u001b[1;32m    922\u001b[0m guarded_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 924\u001b[0m     guarded_code \u001b[38;5;241m=\u001b[39m compile_inner(code, one_graph, hooks, transform)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:666\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_compile.compile_inner\u001b[39m\u001b[38;5;124m\"\u001b[39m, phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentire_frame_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m CompileTimeInstructionCounter\u001b[38;5;241m.\u001b[39mrecord():\n\u001b[0;32m--> 666\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _compile_inner(code, one_graph, hooks, transform)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_utils_internal.py:87\u001b[0m, in \u001b[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39menabled:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39mprofile_compile_time(\n\u001b[1;32m     90\u001b[0m     function, phase_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     91\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:699\u001b[0m, in \u001b[0;36m_compile.<locals>._compile_inner\u001b[0;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[1;32m    697\u001b[0m CompileContext\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mattempt \u001b[38;5;241m=\u001b[39m attempt\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 699\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m transform_code_object(code, transform)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mRestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py:1322\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m   1319\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m   1320\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m-> 1322\u001b[0m transformations(instructions, code_options)\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:219\u001b[0m, in \u001b[0;36mpreserve_global_state.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m exit_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m    216\u001b[0m     torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39m_symbolic_trace\u001b[38;5;241m.\u001b[39m_maybe_revert_all_patches()\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:634\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context), tracer\u001b[38;5;241m.\u001b[39mset_current_tx():\n\u001b[0;32m--> 634\u001b[0m         tracer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnspecializeRestartAnalysis:\n\u001b[1;32m    636\u001b[0m     speculation_log\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2796\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2796\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 983\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep():\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_table[inst\u001b[38;5;241m.\u001b[39mopcode](\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_fn(\u001b[38;5;28mself\u001b[39m, inst)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_context_manager_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.CALL\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[0;32m-> 2279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inst)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[0m, in \u001b[0;36mInstructionTranslatorBase._call\u001b[0;34m(self, inst, call_kw)\u001b[0m\n\u001b[1;32m   2268\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2271\u001b[0m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_function(fn, args, kwargs)\n\u001b[1;32m   2274\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.call_function\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 830\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(fn\u001b[38;5;241m.\u001b[39mcall_function(\u001b[38;5;28mself\u001b[39m, args, kwargs))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/variables/functions.py:727\u001b[0m, in \u001b[0;36mSkipFunctionVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mwarn_once(msg)\n\u001b[1;32m    726\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreason \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 727\u001b[0m unimplemented(msg)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/_dynamo/exc.py:297\u001b[0m, in \u001b[0;36munimplemented\u001b[0;34m(msg, from_exc, case_name)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _NOTHING:\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unsupported(msg, case_name\u001b[38;5;241m=\u001b[39mcase_name) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrom_exc\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Unsupported(msg, case_name\u001b[38;5;241m=\u001b[39mcase_name)\n",
      "\u001b[0;31mUnsupported\u001b[0m: 'skip function disable in file /Users/S_sn/miniconda3/lib/python3.11/site-packages/torch/_dynamo/decorators.py'\n\nfrom user code:\n   File \"/var/folders/ky/gxqpxwvx29ggdsqzf67zslfh0000gn/T/ipykernel_82955/3683954354.py\", line 16, in forward\n    x = torch._dynamo.disable(self.fc)(x)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch = Dim(\"batch\")\n",
    "# Specify that the first dimension of each input is that batch size\n",
    "dynamic_shapes = {\"x\": {0: batch}}\n",
    "ep = export(MyNet(), (torch.randn(2, 10),), dynamic_shapes=dynamic_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = ep.module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_w1'), target='w1', persistent=None),\n",
       " InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_w2'), target='w2', persistent=None),\n",
       " InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc_weight'), target='fc.weight', persistent=None),\n",
       " InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc_bias'), target='fc.bias', persistent=None),\n",
       " InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep.graph_signature.input_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (fc): Module()\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    x, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    w1 = self.w1\n",
      "    w2 = self.w2\n",
      "    fc_weight = self.fc.weight\n",
      "    fc_bias = self.fc.bias\n",
      "    linear = torch.ops.aten.linear.default(x, fc_weight, fc_bias);  x = None\n",
      "    gelu = torch.ops.aten.gelu.default(w2);  w2 = None\n",
      "    matmul = torch.ops.aten.matmul.default(w1, gelu);  gelu = None\n",
      "    tanh = torch.ops.aten.tanh.default(matmul);  matmul = None\n",
      "    matmul_1 = torch.ops.aten.matmul.default(linear, tanh);  linear = tanh = None\n",
      "    pow_1 = torch.ops.aten.pow.Tensor_Scalar(w1, 2);  w1 = None\n",
      "    log_softmax = torch.ops.aten.log_softmax.int(matmul_1, -1)\n",
      "    slice_1 = torch.ops.aten.slice.Tensor(matmul_1, 1, 0, 10);  matmul_1 = None\n",
      "    linear_1 = torch.ops.aten.linear.default(slice_1, fc_weight, fc_bias);  slice_1 = fc_weight = fc_bias = None\n",
      "    mean = torch.ops.aten.mean.default(linear_1);  linear_1 = None\n",
      "    add = torch.ops.aten.add.Tensor(log_softmax, mean);  log_softmax = mean = None\n",
      "    mean_1 = torch.ops.aten.mean.default(pow_1);  pow_1 = None\n",
      "    sub = torch.ops.aten.sub.Tensor(add, mean_1);  add = mean_1 = None\n",
      "    return pytree.tree_unflatten((sub,), self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %input_1 : [num_users=0] = placeholder[target=input_1]\n",
      "    %weight : [num_users=3] = get_attr[target=weight]\n",
      "    %_tensor_constant0 : [num_users=1] = get_attr[target=_tensor_constant0]\n",
      "    %linear : [num_users=1] = call_function[target=torch._C._nn.linear](args = (%_tensor_constant0, %weight, None), kwargs = {})\n",
      "    %getattr_1 : [num_users=1] = call_function[target=builtins.getattr](args = (%weight, shape), kwargs = {})\n",
      "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_1, 0), kwargs = {})\n",
      "    %getattr_2 : [num_users=1] = call_function[target=builtins.getattr](args = (%weight, shape), kwargs = {})\n",
      "    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_2, 1), kwargs = {})\n",
      "    %truediv : [num_users=1] = call_function[target=operator.truediv](args = (%getitem, %getitem_1), kwargs = {})\n",
      "    %pow_1 : [num_users=1] = call_function[target=operator.pow](args = (%truediv, 0.5), kwargs = {})\n",
      "    %mul : [num_users=1] = call_function[target=operator.mul](args = (%linear, %pow_1), kwargs = {})\n",
      "    return mul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:892: UserWarning: Was not able to add assertion to guarantee correct input input to specialized function. It is up to the user to make sure that your inputs match the inputs you specialized the function with.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(torch.fx.symbolic_trace(ScaledLinear(3, 3, bias=False), (torch.randn(2, 3),)).graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, p_fn_weight, p_fn_bias, input):\n",
      "    input_1 = input\n",
      "    linear = torch.ops.aten.linear.default(input_1, p_fn_weight, p_fn_bias);  input_1 = p_fn_weight = p_fn_bias = None\n",
      "    return (linear,)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    },
    {
     "ename": "TraceError",
     "evalue": "Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTraceError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[367], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     w \u001b[38;5;241m=\u001b[39m args[i]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gm\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m*\u001b[39m (w\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m w\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39msymbolic_trace(f)\u001b[38;5;241m.\u001b[39mgraph)\n",
      "File \u001b[0;32m/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:1281\u001b[0m, in \u001b[0;36msymbolic_trace\u001b[0;34m(root, concrete_args)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;124;03mSymbolic tracing API\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;124;03m    GraphModule: a Module created from the recorded operations from ``root``.\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m tracer \u001b[38;5;241m=\u001b[39m Tracer()\n\u001b[0;32m-> 1281\u001b[0m graph \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39mtrace(root, concrete_args)\n\u001b[1;32m   1282\u001b[0m name \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1283\u001b[0m     root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(root, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m root\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   1284\u001b[0m )\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _make_graph_module(tracer\u001b[38;5;241m.\u001b[39mroot, graph, name)\n",
      "File \u001b[0;32m/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:823\u001b[0m, in \u001b[0;36mTracer.trace\u001b[0;34m(self, root, concrete_args)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_search:\n\u001b[1;32m    817\u001b[0m             _autowrap_check(\n\u001b[1;32m    818\u001b[0m                 patcher, module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autowrap_function_ids\n\u001b[1;32m    819\u001b[0m             )\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_node(\n\u001b[1;32m    821\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    822\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 823\u001b[0m             (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_arg(fn(\u001b[38;5;241m*\u001b[39margs)),),\n\u001b[1;32m    824\u001b[0m             {},\n\u001b[1;32m    825\u001b[0m             type_expr\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__annotations__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmodule_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[367]\u001b[0m, in \u001b[0;36mf\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/fx/proxy.py:456\u001b[0m, in \u001b[0;36mProxy.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNPACK_SEQUENCE\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(inst\u001b[38;5;241m.\u001b[39margval))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39miter(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/fx/proxy.py:327\u001b[0m, in \u001b[0;36mTracerBase.iter\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called when a proxy object is being iterated over, such as\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m    when used in control flow.  Normally we don't know what to do because\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    we don't know the value of the proxy, but a custom tracer can attach more\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    information to the graph node using create_node and can choose to return an iterator.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TraceError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy object cannot be iterated. This can be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    328\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattempted when the Proxy is used in a loop or\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    329\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as a *args or **kwargs function argument. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    330\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the torch.fx docs on pytorch.org for a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    331\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmore detailed explanation of what types of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    332\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrol flow can be traced, and check out the\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    333\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Proxy docstring for help troubleshooting \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProxy iteration errors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTraceError\u001b[0m: Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument. See the torch.fx docs on pytorch.org for a more detailed explanation of what types of control flow can be traced, and check out the Proxy docstring for help troubleshooting Proxy iteration errors"
     ]
    }
   ],
   "source": [
    "gm = torch.export.export(nn.Linear(3, 3, bias=True), (torch.randn(2, 3),), dynamic_shapes=dict(input={0: batch})).graph_module\n",
    "print(gm)\n",
    "\n",
    "\n",
    "i = 0\n",
    "def f(*args):\n",
    "    w = args[i]\n",
    "    return gm.forward(*args) * (w.shape[0] / w.shape[1]) ** 0.5\n",
    "\n",
    "print(torch.fx.symbolic_trace(f).graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fn_weight'), target='weight', persistent=None),\n",
       " InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fn_bias'), target='bias', persistent=None),\n",
       " InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='input'), target=None, persistent=None)]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.export.export(nn.Linear(3, 3, bias=True), (torch.randn(2, 3),), dynamic_shapes=dict(input={0: batch})).graph_signature.input_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.fx as fx\n",
    "\n",
    "new_graph = fx.Graph()\n",
    "tracer = torch.fx.proxy.GraphAppendingTracer(new_graph)\n",
    "proxy_args = [fx.Proxy(f'a{i}', tracer) for i in range(3)]\n",
    "\n",
    "ep =  torch.export.export(nn.Linear(3, 3, bias=True), (torch.randn(2, 3),), dynamic_shapes=dict(input={0: batch}))\n",
    "def replacement(ep, *args):\n",
    "    gm = ep.graph_module\n",
    "    weight_ii = {inpspec.target: ii for ii, inpspec in enumerate(ep.graph_signature.input_specs)}['weight']\n",
    "    bias_ii = {inpspec.target: ii for ii, inpspec in enumerate(ep.graph_signature.input_specs)}['bias']\n",
    "    w = args[weight_ii]\n",
    "    return gm.forward(*args) * (w.shape[0] / w.shape[1]) ** 0.5\n",
    "output_proxy = replacement(ep, *proxy_args)\n",
    "\n",
    "gm = ep.graph_module\n",
    "weight_ii = {inpspec.target: ii for ii, inpspec in enumerate(ep.graph_signature.input_specs)}['weight']\n",
    "class M(nn.Module):\n",
    "    def forward(self, *args):\n",
    "        w = args[weight_ii]\n",
    "        return gm.forward(*args) * 2 #(w.shape[0] / w.shape[1]) ** 0.5\n",
    "\n",
    "new_graph = torch.export.export(M(), (torch.randn(2, 3),torch.randn(2), torch.randn(4, 3))).graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %args_0 : [num_users=1] = placeholder[target=args_0]\n",
      "    %args_1 : [num_users=1] = placeholder[target=args_1]\n",
      "    %args_2 : [num_users=1] = placeholder[target=args_2]\n",
      "    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%args_2, %args_0, %args_1), kwargs = {})\n",
      "    return (linear, linear)\n"
     ]
    }
   ],
   "source": [
    "print(new_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledLinear(nn.Linear):\n",
    "    def forward(self, input):\n",
    "        return super().forward(input) * (self.weight.shape[0] / self.weight.shape[1]) ** 0.5\n",
    "\n",
    "batch = Dim(\"batch\")\n",
    "ep =  torch.export.export(ScaledLinear(3, 23, bias=True), (torch.randn(2, 3),), dynamic_shapes=dict(input={0: batch}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %p_weight : [num_users=1] = placeholder[target=p_weight]\n",
      "    %p_bias : [num_users=1] = placeholder[target=p_bias]\n",
      "    %input : [num_users=1] = placeholder[target=input]\n",
      "    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%input, %p_weight, %p_bias), kwargs = {})\n",
      "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%linear, 2.7688746209726918), kwargs = {})\n",
      "    return (mul_2,)\n"
     ]
    }
   ],
   "source": [
    "print(ep.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_weight'), target='weight', persistent=None),\n",
       " InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_bias'), target='bias', persistent=None),\n",
       " InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='input'), target=None, persistent=None)]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep.graph_signature.input_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected `mod` to be an instance of `torch.nn.Module`, got <class 'function'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[414], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m nin \u001b[38;5;241m=\u001b[39m Dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m nout \u001b[38;5;241m=\u001b[39m Dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnout\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m ep \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mexport\u001b[38;5;241m.\u001b[39mexport(replacement, (\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m), weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m), bias\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m)),),\n\u001b[1;32m     12\u001b[0m                           dynamic_shapes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: batch, \u001b[38;5;241m1\u001b[39m: nin}, weight\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: nout, \u001b[38;5;241m1\u001b[39m: nin}, bias\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m: nout})])\n",
      "File \u001b[0;32m/data/vision/torralba/distillation/miniconda3/envs/py312/lib/python3.12/site-packages/torch/export/__init__.py:261\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _export\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `mod` to be an instance of `torch.nn.Module`, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(mod)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m     )\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExporting a ScriptModule is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaybe try converting your ScriptModule to an ExportedProgram \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing `TS2EPConverter(mod, args, kwargs).convert()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected `mod` to be an instance of `torch.nn.Module`, got <class 'function'>."
     ]
    }
   ],
   "source": [
    "class ScaledLinear(nn.Linear):\n",
    "    def forward(self, input):\n",
    "        return super().forward(input) * (self.weight.shape[0] / self.weight.shape[1]) ** 0.5\n",
    "\n",
    "\n",
    "batch = Dim(\"batch\")\n",
    "nin = Dim(\"nin\")\n",
    "nout = Dim(\"nout\")\n",
    "ep =  torch.export.export(ScaledLinear(4, 5, bias=True), (dict(input=torch.randn(2, 4), weight=torch.randn(5, 4), bias=torch.randn(5)),),\n",
    "                          dynamic_shapes=dict(input={0: batch, 1: nin}, weight={0: nout, 1: nin}, bias={0: nout}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch.fx as fx\n",
    "from torch.fx import subgraph_rewriter\n",
    "from torch.fx.passes.utils.matcher_utils import SubgraphMatcher, InternalMatch\n",
    "\n",
    "\n",
    "class ModuleSpec(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def replacement(self, orig_fn, params, buffers, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def PATTERNS_EP(self) -> List[ExportedProgram]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def INPUT_VAR_NAMES(self) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _proxy_trace_replacement_one_pattern(pattern_ep: ExportedProgram, replacement_spec: Callable):\n",
    "        gm = pattern_ep.graph_module\n",
    "        new_graph = fx.Graph()\n",
    "        tracer = torch.fx.proxy.GraphAppendingTracer(new_graph)\n",
    "        proxy_input_kwargs = {}\n",
    "        proxy_param_kwargs = {}\n",
    "        proxy_buffer_kwargs = {}\n",
    "        actual_gm_inputs = []\n",
    "        pattern_input_nodes = {n.target: n for n in filter(lambda n: n.op == \"placeholder\", pattern_ep.graph.nodes)}\n",
    "        replacement_input_nodes = {}\n",
    "        for orig_node in pattern_input_nodes.values():\n",
    "            new_node = new_graph.node_copy(orig_node)\n",
    "            replacement_input_nodes[orig_node.target] = new_node\n",
    "\n",
    "        for input_spec in pattern_ep.graph_signature.input_specs:\n",
    "            original_name = input_spec.target or input_spec.arg.name\n",
    "            proxy = fx.Proxy(replacement_input_nodes[input_spec.arg.name], tracer)\n",
    "            if input_spec.kind == InputKind.PARAMETER:\n",
    "                proxy_param_kwargs[original_name] = proxy\n",
    "            elif input_spec.kind == InputKind.BUFFER:\n",
    "                proxy_buffer_kwargs[original_name] = proxy\n",
    "            else:\n",
    "                proxy_input_kwargs[original_name] = proxy\n",
    "            actual_gm_inputs.append(proxy)\n",
    "\n",
    "        def original_fn(*args, **kwargs):\n",
    "            assert len(args) == 0\n",
    "            assert kwargs.keys() == proxy_input_kwargs.keys()\n",
    "            output = gm.forward(*actual_gm_inputs)\n",
    "\n",
    "            if isinstance(output, tuple) and len(output) == 1:\n",
    "                output = output[0]\n",
    "            return output\n",
    "\n",
    "        output_proxy = replacement_spec(original_fn, proxy_param_kwargs, proxy_buffer_kwargs, **proxy_input_kwargs)\n",
    "\n",
    "        new_graph.output(\n",
    "            torch.utils._pytree.tree_map(lambda x: x.node, output_proxy),\n",
    "        )\n",
    "        return new_graph\n",
    "\n",
    "    def _execute_pass_one_pattern(self, ep: ExportedProgram, pattern_ep: ExportedProgram):\n",
    "        # 0: test if match is valid, i.e., interacting with parameters\n",
    "        # 1. modifies graph in place if needed\n",
    "        # 2. get initializers for the parameters\n",
    "        # 3. get the normalizers for the parameters\n",
    "        ep_params = set(spec.arg.name for spec in ep.graph_signature.input_specs)\n",
    "\n",
    "        def match_filter(match: InternalMatch, orig_graph: fx.Graph, pattern_graph: fx.Graph):\n",
    "            for pattern_node, full_node in match.nodes_map.items():\n",
    "                if pattern_node.op != 'placeholder':\n",
    "                    continue\n",
    "                if pattern_node.name in self.INPUT_VAR_NAMES:\n",
    "                    continue\n",
    "                if full_node.target not in ep_params:\n",
    "                    return False  # not interacting with parameters\n",
    "            return True\n",
    "\n",
    "        replacement_graph = self._proxy_trace_replacement_one_pattern(pattern_ep, self.replacement)\n",
    "        return subgraph_rewriter.replace_pattern_with_filters(ep.graph_module, pattern_ep.graph, replacement_graph, match_filters=[match_filter])\n",
    "\n",
    "\n",
    "    def __call__(self, ep: ExportedProgram):\n",
    "        num_replaced = 0\n",
    "        for pattern_ep in self.PATTERNS_EP:\n",
    "            num_replaced += len(self._execute_pass_one_pattern(ep, pattern_ep))\n",
    "        return num_replaced\n",
    "\n",
    "\n",
    "class FCModulaSpec(ModuleSpec):\n",
    "    _DYNAMIC_DIMS = dict(batch=Dim(\"batch\"))\n",
    "    PATTERNS_EP = [\n",
    "        torch.export.export(nn.Linear(3, 3, bias=True), (torch.randn(2, 3),), dynamic_shapes=dict(input={0: _DYNAMIC_DIMS['batch']})),\n",
    "        torch.export.export(nn.Linear(3, 3, bias=False), (torch.randn(2, 3),), dynamic_shapes=dict(input={0: _DYNAMIC_DIMS['batch']})),\n",
    "    ]\n",
    "    INPUT_VAR_NAMES = ['input']\n",
    "\n",
    "    @staticmethod\n",
    "    def replacement(orig_fn, params, buffers, *args, **kwargs):\n",
    "        return orig_fn(*args, **kwargs) * (params['weight'].shape[0] / params['weight'].shape[1]) ** 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = export(MyNet(), (torch.randn(2, 10),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %p_w1 : [num_users=2] = placeholder[target=p_w1]\n",
      "    %p_w2 : [num_users=1] = placeholder[target=p_w2]\n",
      "    %p_fc_weight : [num_users=3] = placeholder[target=p_fc_weight]\n",
      "    %p_fc_bias : [num_users=3] = placeholder[target=p_fc_bias]\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %gelu : [num_users=1] = call_function[target=torch.ops.aten.gelu.default](args = (%p_w2,), kwargs = {})\n",
      "    %matmul : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%p_w1, %gelu), kwargs = {})\n",
      "    %tanh : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%matmul,), kwargs = {})\n",
      "    %matmul_1 : [num_users=2] = call_function[target=torch.ops.aten.matmul.default](args = (%linear, %tanh), kwargs = {})\n",
      "    %pow_1 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%p_w1, 2), kwargs = {})\n",
      "    %log_softmax : [num_users=1] = call_function[target=torch.ops.aten.log_softmax.int](args = (%matmul_1, -1), kwargs = {})\n",
      "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%matmul_1, 1, 0, 10), kwargs = {})\n",
      "    %linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_1, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%linear_1,), kwargs = {})\n",
      "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%log_softmax, %mean), kwargs = {})\n",
      "    %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%pow_1,), kwargs = {})\n",
      "    %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul, %mean_1), kwargs = {})\n",
      "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 1, 0, 10), kwargs = {})\n",
      "    %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%slice_2,), kwargs = {})\n",
      "    %linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%abs_1, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%linear_2,), kwargs = {})\n",
      "    return (mean_2,) [InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_w1'), target='w1', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_w2'), target='w2', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc_weight'), target='fc.weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_fc_bias'), target='fc.bias', persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)]\n"
     ]
    }
   ],
   "source": [
    "print(ep.graph, ep.graph_signature.input_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FCModulaSpec()(ep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %p_w1 : [num_users=2] = placeholder[target=p_w1]\n",
      "    %p_w2 : [num_users=1] = placeholder[target=p_w2]\n",
      "    %p_fc_weight : [num_users=9] = placeholder[target=p_fc_weight]\n",
      "    %p_fc_bias : [num_users=3] = placeholder[target=p_fc_bias]\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %gelu : [num_users=1] = call_function[target=torch.ops.aten.gelu.default](args = (%p_w2,), kwargs = {})\n",
      "    %matmul : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%p_w1, %gelu), kwargs = {})\n",
      "    %tanh : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%matmul,), kwargs = {})\n",
      "    %linear_default : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %getattr_1 : [num_users=1] = call_function[target=builtins.getattr](args = (%p_fc_weight, shape), kwargs = {})\n",
      "    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_1, 0), kwargs = {})\n",
      "    %getattr_2 : [num_users=1] = call_function[target=builtins.getattr](args = (%p_fc_weight, shape), kwargs = {})\n",
      "    %getitem_1 : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_2, 1), kwargs = {})\n",
      "    %truediv : [num_users=1] = call_function[target=operator.truediv](args = (%getitem, %getitem_1), kwargs = {})\n",
      "    %pow_2 : [num_users=1] = call_function[target=operator.pow](args = (%truediv, 0.5), kwargs = {})\n",
      "    %mul_1 : [num_users=1] = call_function[target=operator.mul](args = (%linear_default, %pow_2), kwargs = {})\n",
      "    %matmul_1 : [num_users=2] = call_function[target=torch.ops.aten.matmul.default](args = (%mul_1, %tanh), kwargs = {})\n",
      "    %pow_1 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%p_w1, 2), kwargs = {})\n",
      "    %log_softmax : [num_users=1] = call_function[target=torch.ops.aten.log_softmax.int](args = (%matmul_1, -1), kwargs = {})\n",
      "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%matmul_1, 1, 0, 10), kwargs = {})\n",
      "    %linear_default_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_1, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %getattr_3 : [num_users=1] = call_function[target=builtins.getattr](args = (%p_fc_weight, shape), kwargs = {})\n",
      "    %getitem_2 : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_3, 0), kwargs = {})\n",
      "    %getattr_4 : [num_users=1] = call_function[target=builtins.getattr](args = (%p_fc_weight, shape), kwargs = {})\n",
      "    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_4, 1), kwargs = {})\n",
      "    %truediv_1 : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_2, %getitem_3), kwargs = {})\n",
      "    %pow_3 : [num_users=1] = call_function[target=operator.pow](args = (%truediv_1, 0.5), kwargs = {})\n",
      "    %mul_2 : [num_users=1] = call_function[target=operator.mul](args = (%linear_default_1, %pow_3), kwargs = {})\n",
      "    %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%mul_2,), kwargs = {})\n",
      "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%log_softmax, %mean), kwargs = {})\n",
      "    %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%pow_1,), kwargs = {})\n",
      "    %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul, %mean_1), kwargs = {})\n",
      "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 1, 0, 10), kwargs = {})\n",
      "    %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%slice_2,), kwargs = {})\n",
      "    %linear_default_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%abs_1, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %getattr_5 : [num_users=1] = call_function[target=builtins.getattr](args = (%p_fc_weight, shape), kwargs = {})\n",
      "    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_5, 0), kwargs = {})\n",
      "    %getattr_6 : [num_users=1] = call_function[target=builtins.getattr](args = (%p_fc_weight, shape), kwargs = {})\n",
      "    %getitem_5 : [num_users=1] = call_function[target=operator.getitem](args = (%getattr_6, 1), kwargs = {})\n",
      "    %truediv_2 : [num_users=1] = call_function[target=operator.truediv](args = (%getitem_4, %getitem_5), kwargs = {})\n",
      "    %pow_4 : [num_users=1] = call_function[target=operator.pow](args = (%truediv_2, 0.5), kwargs = {})\n",
      "    %mul_3 : [num_users=1] = call_function[target=operator.mul](args = (%linear_default_2, %pow_4), kwargs = {})\n",
      "    %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%mul_3,), kwargs = {})\n",
      "    return (mean_2,)\n"
     ]
    }
   ],
   "source": [
    "print(ep.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %p_w1 : [num_users=2] = placeholder[target=p_w1]\n",
      "    %p_w2 : [num_users=1] = placeholder[target=p_w2]\n",
      "    %p_fc_weight : [num_users=3] = placeholder[target=p_fc_weight]\n",
      "    %p_fc_bias : [num_users=3] = placeholder[target=p_fc_bias]\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %gelu : [num_users=1] = call_function[target=torch.ops.aten.gelu.default](args = (%p_w2,), kwargs = {})\n",
      "    %matmul : [num_users=1] = call_function[target=torch.ops.aten.matmul.default](args = (%p_w1, %gelu), kwargs = {})\n",
      "    %tanh : [num_users=1] = call_function[target=torch.ops.aten.tanh.default](args = (%matmul,), kwargs = {})\n",
      "    %linear : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%x, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%linear, 1.4142135623730951), kwargs = {})\n",
      "    %matmul_1 : [num_users=2] = call_function[target=torch.ops.aten.matmul.default](args = (%mul, %tanh), kwargs = {})\n",
      "    %pow_1 : [num_users=1] = call_function[target=torch.ops.aten.pow.Tensor_Scalar](args = (%p_w1, 2), kwargs = {})\n",
      "    %log_softmax : [num_users=1] = call_function[target=torch.ops.aten.log_softmax.int](args = (%matmul_1, -1), kwargs = {})\n",
      "    %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%matmul_1, 1, 0, 10), kwargs = {})\n",
      "    %linear_1 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%slice_1, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %mul_1 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%linear_1, 1.4142135623730951), kwargs = {})\n",
      "    %mean : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%mul_1,), kwargs = {})\n",
      "    %mul_2 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%log_softmax, %mean), kwargs = {})\n",
      "    %mean_1 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%pow_1,), kwargs = {})\n",
      "    %sub : [num_users=1] = call_function[target=torch.ops.aten.sub.Tensor](args = (%mul_2, %mean_1), kwargs = {})\n",
      "    %slice_2 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%sub, 1, 0, 10), kwargs = {})\n",
      "    %abs_1 : [num_users=1] = call_function[target=torch.ops.aten.abs.default](args = (%slice_2,), kwargs = {})\n",
      "    %linear_2 : [num_users=1] = call_function[target=torch.ops.aten.linear.default](args = (%abs_1, %p_fc_weight, %p_fc_bias), kwargs = {})\n",
      "    %mul_3 : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%linear_2, 1.4142135623730951), kwargs = {})\n",
      "    %mean_2 : [num_users=1] = call_function[target=torch.ops.aten.mean.default](args = (%mul_3,), kwargs = {})\n",
      "    return (mean_2,)\n"
     ]
    }
   ],
   "source": [
    "eep = export(ep.module(), (torch.randn(2, 10),))\n",
    "print(eep.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0241, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eep.module()(torch.randn(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_function linear aten.linear.default (input, p_fn_weight, p_fn_bias)\n",
      "FakeTensor(..., size=(s0, 3))\n",
      "placeholder input input ()\n",
      "FakeTensor(..., size=(s0, 3))\n",
      "placeholder p_fn_weight p_fn_weight ()\n",
      "FakeTensor(..., size=(3, 3), requires_grad=True)\n",
      "p_fn_weight {'p_fn_bias', 'input', 'p_fn_weight'}\n",
      "placeholder p_fn_bias p_fn_bias ()\n",
      "FakeTensor(..., size=(3,), requires_grad=True)\n",
      "p_fn_bias {'p_fn_bias', 'input', 'p_fn_weight'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_filter(fc_pms[0].match(ep.graph)[0], ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name         target              args                         kwargs\n",
      "-------------  -----------  ------------------  ---------------------------  --------\n",
      "placeholder    p__bias_1    p__bias_1           ()                           {}\n",
      "placeholder    p__weight_1  p__weight_1         ()                           {}\n",
      "placeholder    x            x                   ()                           {}\n",
      "call_function  addmm        aten.addmm.default  (p__bias_1, x, p__weight_1)  {}\n",
      "output         output       output              ((addmm,),)                  {}\n"
     ]
    }
   ],
   "source": [
    "pattern_graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransform(torch.fx.Transformer):\n",
    "    \"\"\"\n",
    "    Original:\n",
    "        def f(x, w):\n",
    "            return x @ w.T\n",
    "\n",
    "        def f(x, w):\n",
    "            return x @ w.T\n",
    "\n",
    "    After pass:\n",
    "        def f(x, y):\n",
    "            z = x * y\n",
    "            return z - y\n",
    "    \"\"\"\n",
    "    def call_function(self, target, args, kwargs):\n",
    "        if target != torch.ops.aten.add.Tensor:\n",
    "            return super().call_function(target, args, kwargs)\n",
    "\n",
    "        x, y = args\n",
    "\n",
    "        mul_res = super().call_function(torch.ops.aten.mul.Tensor, args, {})\n",
    "        return super().call_function(torch.ops.aten.sub.Tensor, (mul_res, y), {})\n",
    "\n",
    "transformed_graph_module = ReplaceAddWithMulSub(graph_module).transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import fx\n",
    "\n",
    "def transform(m: torch.nn.Module,\n",
    "              tracer_class : type = fx.Tracer) -> fx.GraphModule:\n",
    "    graph : fx.Graph = tracer_class().trace(m)\n",
    "    # FX represents its Graph as an ordered list of\n",
    "    # nodes, so we can iterate through them.\n",
    "    # for node in graph.nodes:\n",
    "        # Checks if we're calling a function (i.e:\n",
    "        # torch.add)\n",
    "        # if node.op == 'call_function':\n",
    "        #     # The target attribute is the function\n",
    "        #     # that call_function calls.\n",
    "        #     # if node.target == torch.add:\n",
    "        #     #     node.target = torch.mul\n",
    "        #     print(node)\n",
    "\n",
    "    graph.lint() # Does some checks to make sure the\n",
    "                 # Graph is well-formed.\n",
    "\n",
    "    return fx.GraphModule(m, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name      target               args                     kwargs\n",
      "-------------  --------  -------------------  -----------------------  --------\n",
      "get_attr       weight    weight               ()                       {}\n",
      "get_attr       bias      bias                 ()                       {}\n",
      "placeholder    input_1   input                ()                       {}\n",
      "call_function  linear    aten.linear.default  (input_1, weight, bias)  {}\n",
      "output         output_1  output               ((linear,),)             {}\n"
     ]
    }
   ],
   "source": [
    "export(nn.Linear(10, 20),( torch.randn(2, 10),)).module().graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name         target               args                             kwargs\n",
      "-------------  -----------  -------------------  -------------------------------  --------\n",
      "placeholder    p_fn_weight  p_fn_weight          ()                               {}\n",
      "placeholder    p_fn_bias    p_fn_bias            ()                               {}\n",
      "placeholder    input        input                ()                               {}\n",
      "call_function  linear       aten.linear.default  (input, p_fn_weight, p_fn_bias)  {}\n",
      "output         output       output               ((linear,),)                     {}\n"
     ]
    }
   ],
   "source": [
    "export(nn.Linear(10, 20),( torch.randn(2, 10),)).graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name       target                args                 kwargs\n",
      "-------------  ---------  --------------------  -------------------  --------\n",
      "get_attr       fc_weight  fc.weight             ()                   {}\n",
      "get_attr       fc_bias    fc.bias               ()                   {}\n",
      "placeholder    x          x                     ()                   {}\n",
      "call_function  permute    aten.permute.default  (fc_weight, [1, 0])  {}\n",
      "call_function  matmul     aten.matmul.default   (x, permute)         {}\n",
      "call_function  add        aten.add.Tensor       (matmul, fc_bias)    {}\n",
      "output         output_1   output                ((add,),)            {}\n"
     ]
    }
   ],
   "source": [
    "export(MyNet(),( torch.randn(2, 10),)).module().graph.print_tabular()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.fx.passes.infra.pass_manager import PassManager\n",
    "\n",
    "pm = PassManager(\n",
    "    passes=[replace_add_with_div, replace_div_with_mul],\n",
    "    run_checks_after_each_pass=True,\n",
    "    suppress_check_failures=False,\n",
    ")\n",
    "graph_module_out = pm(graph_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._dynamo.backends.inductor.inductor(*args, **kwargs)>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inductor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, L_self_modules_fc_parameters_weight_: \"f32[20, 10]\", L_x_: \"f32[10]\", L_self_modules_fc_parameters_bias_: \"f32[20]\"):\n",
      "        l_self_modules_fc_parameters_weight_ = L_self_modules_fc_parameters_weight_\n",
      "        l_x_ = L_x_\n",
      "        l_self_modules_fc_parameters_bias_ = L_self_modules_fc_parameters_bias_\n",
      "        \n",
      "         # File: /tmp/ipykernel_1341723/3769743237.py:13 in forward, code: return x @ z.T + self.fc.bias\n",
      "        getattr_1: \"f32[10, 20]\" = l_self_modules_fc_parameters_weight_.T;  l_self_modules_fc_parameters_weight_ = None\n",
      "        matmul: \"f32[20]\" = l_x_ @ getattr_1;  l_x_ = getattr_1 = None\n",
      "        add: \"f32[20]\" = matmul + l_self_modules_fc_parameters_bias_;  matmul = l_self_modules_fc_parameters_bias_ = None\n",
      "        return (add,)\n",
      "        \n",
      "<function _create_runtime_wrapper.<locals>.runtime_wrapper at 0x7fa9868b2160>\n"
     ]
    }
   ],
   "source": [
    "import torch._dynamo\n",
    "from torch._functorch.aot_autograd import aot_module, aot_module_simplified\n",
    "from torch._dynamo.backends.common import aot_autograd\n",
    "from functorch.compile import make_boxed_func\n",
    "from torch._decomp import core_aten_decompositions\n",
    "from torch._dynamo.backends.inductor import inductor\n",
    "\n",
    "\n",
    "def pattern(x, w):\n",
    "    return x @ w.T\n",
    "    return lerpo_1 + torch.zeros_like(y).sum()\n",
    "    zeros_like = torch.ops.aten.zeros_like.default(x, pin_memory = False)\n",
    "    lerp = torch.ops.aten.lerp.Scalar(x, zeros_like, 0.5)\n",
    "    return lerp\n",
    "\n",
    "pattern = torch.fx.symbolic_trace(nn.Linear.forward).graph\n",
    "\n",
    "def linear_update(x, w):\n",
    "    nout, nin = w.shape\n",
    "    return (x @ w.T) * (nout / nin) ** 0.5\n",
    "    with torch.no_grad():\n",
    "        weight.sub_(1)\n",
    "    return weight @ x\n",
    "\n",
    "def replacement(x, y):\n",
    "    return linear_update(x, y)\n",
    "    return x / 12\n",
    "    return torch.ops.aten.div.Scalar(x, 12)\n",
    "\n",
    "# Backends can further finetune the decompositions if needed\n",
    "# Available decompositions can be found in\n",
    "# torch/_decomp/decompositions.py and torch/_refs/__init__.py\n",
    "decompositions = core_aten_decompositions()\n",
    "decompositions.update(\n",
    "    torch._decomp.get_decompositions([\n",
    "        # torch.ops.aten.addmm,\n",
    "    ])\n",
    ")\n",
    "\n",
    "# def my_compiler(gm, example_inputs):\n",
    "#     gm.print_readable()\n",
    "#     return make_boxed_func(gm.forward)\n",
    "\n",
    "# my_backend = aot_autograd(fw_compiler=my_compiler, decompositions=decompositions)  # bw_compiler=my_compiler\n",
    "\n",
    "def my_backend(gm, sample_inputs):\n",
    "\n",
    "    gm.print_readable()\n",
    "\n",
    "    gm = fn = inductor(gm, sample_inputs)\n",
    "\n",
    "    def get_closure_vars(fn):\n",
    "        closure_vars = fn.__code__.co_freevars\n",
    "        closure_values = [cell.cell_contents for cell in fn.__closure__]\n",
    "\n",
    "        closure_dict = dict(zip(closure_vars, closure_values))\n",
    "        return closure_dict\n",
    "    print(get_closure_vars(get_closure_vars(fn)['fn'])['compiled_fn'])\n",
    "    return gm\n",
    "\n",
    "    def my_compiler(gm, sample_inputs):\n",
    "        # <implement your compiler here>\n",
    "        print(\"Decomposed fx Graph in Aten IR:\")\n",
    "        gm.print_readable()\n",
    "        from torch._inductor.compile_fx import compile_fx\n",
    "        gm = compile_fx(gm, sample_inputs)\n",
    "        return gm\n",
    "\n",
    "    gm.print_readable()\n",
    "\n",
    "    # Invoke AOTAutograd\n",
    "    return aot_module_simplified(\n",
    "        gm,\n",
    "        sample_inputs,\n",
    "        # decompositions=decompositions,\n",
    "        fw_compiler=my_compiler,\n",
    "    )\n",
    "\n",
    "# model_opt = torch.compile(model, backend=my_backend)\n",
    "\n",
    "torch._dynamo.reset()\n",
    "m = MyNet()\n",
    "# gm = torch.fx.symbolic_trace(m)\n",
    "# gm.print_readable()\n",
    "\n",
    "# def match_filter(match, full_graph: fx.Graph, pattern_graph: fx.Graph):\n",
    "#     return is_node_a_parameter(match.placeholder_nodes[1], full_graph)\n",
    "#     pattern_graph.print_tabular()\n",
    "#     full_graph.print_tabular()\n",
    "#     return True\n",
    "\n",
    "# def is_node_a_parameter(node: fx.Node, graph: fx.Graph):\n",
    "#     matches = graph.find_nodes(op='placeholder', target=node.target)  # check reassignment\n",
    "#     if len(matches) == 0:\n",
    "#         # check if node is a parameter\n",
    "#         matches: List[fx.Node] = graph.find_nodes(op='get_attr', target=node.target)\n",
    "#         print(matches[0].target, matches[0].args, matches[0].kwargs)\n",
    "#         if len(matches) == 1:\n",
    "#             return matches[0].target in dict(graph.owning_module.named_parameters()).keys()\n",
    "#         else:\n",
    "#             return False\n",
    "#     else:\n",
    "#         assert len(matches) == 1\n",
    "#         return is_node_a_parameter(matches[0], graph)\n",
    "\n",
    "\n",
    "matches = subgraph_rewriter.replace_pattern_with_filters(gm, pattern, replacement, match_filters=[match_filter])\n",
    "# gm.print_readable()\n",
    "\n",
    "# fn = torch.compile(backend=my_backend, dynamic=False)(m)\n",
    "fn = torch.compile(m, backend=my_backend)  # now inductor\n",
    "\n",
    "# triggers compilation of forward graph on the first run\n",
    "out = fn(torch.randn(10).requires_grad_())\n",
    "\n",
    "# triggers compilation of backward graph on the first run\n",
    "out.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833,\n",
      "        0.0833])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(10).requires_grad_()\n",
    "y = fn(x)\n",
    "y.sum().backward()\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %fc_weight : [num_users=1] = get_attr[target=fc.weight]\n",
      "    %getattr_1 : [num_users=1] = call_function[target=builtins.getattr](args = (%fc_weight, T), kwargs = {})\n",
      "    %matmul : [num_users=1] = call_function[target=operator.matmul](args = (%x, %getattr_1), kwargs = {})\n",
      "    %fc_bias : [num_users=1] = get_attr[target=fc.bias]\n",
      "    %add : [num_users=1] = call_function[target=operator.add](args = (%matmul, %fc_bias), kwargs = {})\n",
      "    return add\n"
     ]
    }
   ],
   "source": [
    "print(transform(MyNet()).graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0517, -2.6862, -3.1141, -8.1104, -2.9862, -7.3861, -4.0215, -1.2740,\n",
       "        -8.7361, -3.5379, -3.8972, -3.1834, -5.1621, -2.6338, -6.4533, -7.8579,\n",
       "        -6.3711, -5.7606, -4.3582, -6.9796],\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.compile(fullgraph=True)(transform(MyNet()))\n",
    "c(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%x,), kwargs = {})\n",
      "    %w1 : [num_users=2] = get_attr[target=w1]\n",
      "    %w2 : [num_users=1] = get_attr[target=w2]\n",
      "    %matmul : [num_users=1] = call_function[target=operator.matmul](args = (%w1, %w2), kwargs = {})\n",
      "    %tanh : [num_users=1] = call_method[target=tanh](args = (%matmul,), kwargs = {})\n",
      "    %matmul_1 : [num_users=1] = call_function[target=operator.matmul](args = (%fc, %tanh), kwargs = {})\n",
      "    %pow_1 : [num_users=0] = call_method[target=pow](args = (%w1, 2), kwargs = {})\n",
      "    %log_softmax : [num_users=1] = call_function[target=torch.nn.functional.log_softmax](args = (%matmul_1,), kwargs = {dim: -1, _stacklevel: 3, dtype: None})\n",
      "    return log_softmax\n"
     ]
    }
   ],
   "source": [
    "print(c.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'241018_300steps_bzs2048/orth_muon_norm_jb_target_ema_grad_norm2_sqrt_lr0.0008_seed0.pth'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, subprocess\n",
    "import datetime, time\n",
    "from IPython.display import display\n",
    "from time import sleep\n",
    "\n",
    "# print('Test 1')\n",
    "# sleep(1)\n",
    "# dh.update('Test3')\n",
    "\n",
    "uuid = '5be55e'\n",
    "\n",
    "\n",
    "class printed_str(str):\n",
    "    def __repr__(self):\n",
    "       return self\n",
    "\n",
    "dh = display('slurm status',display_id=True)\n",
    "while True:\n",
    "    # print human readable time\n",
    "    time_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # dh.update(printed_str(time_str))\n",
    "    out = json.loads(subprocess.getoutput('sacct --json -S 10/24-19:20'))\n",
    "    jobs = {j['job_id']: j for j in out['jobs']}\n",
    "    jobs = {k: j for k, j in jobs.items() if j['name'].endswith('-' + uuid)}\n",
    "\n",
    "    pending = running = failed = successful = 0\n",
    "    for _, j in jobs.items():\n",
    "        state = j['state']['current'][0]\n",
    "        if state == 'PENDING':\n",
    "            pending += 1\n",
    "        elif state == 'RUNNING':\n",
    "            running += 1\n",
    "        elif state == 'FAILED':\n",
    "            failed += 1\n",
    "        elif state == 'COMPLETED':\n",
    "            if j['exit_code']['status'][0] == 'SUCCESS':\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "        else:\n",
    "            raise ValueError(f'Unknown state: {j[\"state\"]}')\n",
    "    dh.update(printed_str(f'''{time_str}\n",
    "Pending: {pending}, Running: {running}, Failed: {failed}, Successful: {successful}\n",
    "'''))\n",
    "    if running + pending == 0:\n",
    "        break\n",
    "    time.sleep(2)\n",
    "    # now delete last two lines of output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "set +e\n",
      "\n",
      "START_TIME=$(date +\"%m/%d/%y-%H:%M\")\n",
      "UUID6=$(echo -n $(date +%s%N) | md5sum | fold -w6 | shuf | head -n1)\n",
      "\n",
      "echo \"START_TIME=$START_TIME\"\n",
      "echo \"UUID=$UUID6\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reload_module()\n",
    "\n",
    "lr_sm = [1e-7, 3e-7, 5e-7, 8e-7, 1e-6, 3e-6, 5e-6, 8e-6, 1e-5, 3e-5, 5e-5, 8e-5, 1e-4, 3e-4, 5e-4, 8e-4, 1e-3, 3e-3, 5e-3, 8e-3]\n",
    "lr_lg = [1e-2, 3e-2, 5e-2, 8e-2, 1e-1, 3e-1, 5e-1, 8e-1, 1]\n",
    "lrs = lr_sm + lr_lg\n",
    "\n",
    "optims = sorted(OPTIM_MAP.keys())\n",
    "\n",
    "print('''#!/bin/bash\n",
    "\n",
    "set +e\n",
    "\n",
    "START_TIME=$(date +\"%m/%d/%y-%H:%M\")\n",
    "UUID6=$(echo -n $(date +%s%N) | md5sum | fold -w6 | shuf | head -n1)\n",
    "''')\n",
    "\n",
    "seed = 0\n",
    "for lr in lrs:\n",
    "    for optim_kind in optims:\n",
    "        # if 'sign' not in optim:--\n",
    "        #     continue\n",
    "        file = f'241018_300steps_bzs2048/orth_{optim_kind}_lr{lr:g}_seed{seed}.pth'\n",
    "        if os.path.exists(file):\n",
    "            continue\n",
    "        print(f\"python /data/vision/phillipi/contrastive/tongzhou/qrl2/scripts/sbatch.py -g nvidia_h100_80gb_hbm3 nvidia_h100_nvl nvidia_a100-sxm4-80gb tesla_v100-sxm2-32gb nvidia_rtx_6000_ada_generation -uuid $UUID6 -q -e py312 {optim_kind}_{lr:g} -- python -u 241018_muon_renorm.py {optim_kind} {lr:g} 0\")\n",
    "        # if os.path.exists(file + '.running'):\n",
    "        #     with open(file + '.running', 'r') as f:\n",
    "        #         line = f.readline().strip()\n",
    "        #         if line != '0':\n",
    "        #             raise ValueError(f'{file} is not done')\n",
    "        #     continue\n",
    "\n",
    "print('echo \"START_TIME=$START_TIME\"')\n",
    "print('echo \"UUID=$UUID6\"')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3066\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(broken_sd)\n",
    "data, target = data_target\n",
    "with torch.no_grad():\n",
    "    output = model(data.flatten(1))\n",
    "    loss = F.cross_entropy(output, target)\n",
    "print(f'Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model functional function of input and state dict\n",
    "def func_call(param, input):\n",
    "    return torch.func.functional_call(model, param, input)\n",
    "\n",
    "bfunc_call = torch.vmap(func_call, in_dims=(-1, None), out_dims=(0,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = torch.linspace(-1.5, 1.5, 500).to(torch.bfloat16).cuda()\n",
    "interp_sd = {\n",
    "    k: torch.lerp(pre_broken_sd[k][..., None], broken_sd[k][..., None], ws) for k in pre_broken_sd.keys()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp_losses = F.cross_entropy(bfunc_call(interp_sd, data.flatten(1)).flatten(0, 1), target.expand(ws.shape[0], -1).flatten(0, 1), reduction='none').unflatten(0, (ws.shape[0], -1)).mean(-1).cpu().data.to(torch.float32)\n",
    "\n",
    "plt.plot(\n",
    "    ws.cpu().data.to(torch.float32),\n",
    "    interp_losses,\n",
    ")\n",
    "plt.axvline(0, c='k', ls='--', alpha=0.25)\n",
    "plt.axhline(loss.item(), c='k', ls='--', alpha=0.25)\n",
    "plt.axhline(0, c='k', ls='--', alpha=0.25)\n",
    "plt.axvline(1, c='k', ls='--', alpha=0.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.cosine_similarity(updates[0:40].flatten(-2, -1)[:, None, :], grads[0:40].flatten(-2, -1)[None, :, :], dim=-1).cpu().data, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(F.cosine_similarity(updates[:30].flatten(-2, -1), grads[:30].flatten(-2, -1), dim=-1).cpu().data)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://isola-h100-1.csail.mit.edu:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://isola-h100-1.csail.mit.edu:8888/'. Verify the server is running and reachable. (request to http://isola-h100-1.csail.mit.edu:8888/api/kernels?1729574932733 failed, reason: connect ECONNREFUSED 128.30.195.12:8888).)."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "for file in sorted(glob.glob('241018_300steps_bzs2048/orth*.running')):\n",
    "    print(file)\n",
    "    # os.rename(file, file.replace('muon_norm_fro_target', 'muon_norm_fro_exact_target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x750 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(32, 10), dpi=75)\n",
    "plt.plot(steps, (grads.flatten(-2, -1).norm(dim=-1)).cpu().data, label='||grad||_F', alpha=0.5)\n",
    "plt.plot(steps, (momentums.flatten(-2, -1).norm(dim=-1)).cpu().data, label='||momentum||_F', zorder=100)\n",
    "plt.plot(steps, (updates.flatten(-2, -1).norm(dim=-1)).cpu().data, label='||NS(momentum)||_F')\n",
    "plt.plot(steps, (gnorms).cpu().data, label='update_norm := ||NS(momentum)||_rms', zorder=100)\n",
    "plt.plot(steps, (target_norms).cpu().data, label='target_norm', zorder=100)\n",
    "plt.plot(steps, (target_norms / gnorms * updates.flatten(-2, -1).norm(dim=-1)).cpu().data, label='||UPDATE := NS(momentum) * target_norm / update_norm||_F', lw=2)\n",
    "# plt.plot(steps, (momentum_0thpowers.flatten(-2, -1).norm(dim=-1)).cpu().data, label='momentum_0thpower norm')\n",
    "plt.axhline(min(grads.shape[-2:]) ** 0.5, c='k', ls='--', alpha=0.25, zorder=100)\n",
    "plt.plot(steps, torch.as_tensor(losses).exp().cpu().data, label='exp(loss)', alpha=0.75)\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# cap ylim to be no smaller than 1e-6 and no larger than 1e12\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.ylim(max(ymin, 1e-12), min(ymax, 1e6))\n",
    "# plt.xlim(0, 30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
