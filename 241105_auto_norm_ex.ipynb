{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `auto_norm` to compute output norms and optimize scaling factors\n",
    "\n",
    "We go through three examples using `auto_norm`:\n",
    "1. Compute norms automatically for regular PyTorch modules\n",
    "2. Build modula norm automatically for regular PyTorch modules\n",
    "3. Optimize scaling factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1: compute norms automatically for regular PyTorch modules\n",
    "\n",
    "Let's define a usual network in normal PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyResBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auto_norm` provides computation on `auto_norm.NormedTensorBase` subclasses, including \n",
    "+ `RMS_NormTensor`, \n",
    "+ `RMS_RMS_NormTensor`, \n",
    "+ `L1_NormTensor` and \n",
    "+ `Linf_NormTensor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`auto_norm.build_norm_map` is the key entrypoint, it returns a `norm_map` function that computes computes (norms of inputs, norms of parameters, norms of buffers) -> norms of outputs.\n",
    "\n",
    "Its syntax is\n",
    "\n",
    "```py\n",
    "def build_norm_map(module: nn.Module, *example_args, dynamic_shapes: Optional = None, **example_kwargs):\n",
    "    ...\n",
    "\n",
    "    def norm_map(*normed_args, normed_state_dict, **normed_kwargs):\n",
    "        # normed_* should generally contain auto_norm.*_NormTensor, instead of usual torch.Tensor\n",
    "        ...\n",
    "        return normed_outputs\n",
    "\n",
    "    return norm_map\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import auto_norm\n",
    "\n",
    "net = MyResBlock()\n",
    "example_input = torch.randn(10, 8, requires_grad=True)\n",
    "\n",
    "norm_map = auto_norm.build_norm_map(net, example_input)  # can also specify dynamic dims (e.g., batch), but not necessary for this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct normed input and state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_input: \n",
      " RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1,), ...)\n"
     ]
    }
   ],
   "source": [
    "normed_input = auto_norm.RMS_NormTensor(1, elem_dims=(-1,))\n",
    "print('normed_input: \\n', normed_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_state_dict:\n",
      "{'net.0.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.0.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.2.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.2.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.4.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.4.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...)}\n"
     ]
    }
   ],
   "source": [
    "normed_state_dict = {}\n",
    "for name in net.state_dict():\n",
    "    if name.endswith('weight'):\n",
    "        normed_state_dict[name] = auto_norm.RMS_RMS_NormTensor(1, elem_dims=(-1, -2))  # elem_dims means which dims to norm over\n",
    "    elif name.endswith('bias'):\n",
    "        normed_state_dict[name] = auto_norm.RMS_NormTensor(0, elem_dims=(-1,))\n",
    "\n",
    "print('normed_state_dict:')\n",
    "from pprint import pprint\n",
    "pprint(normed_state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `norm_map` to compute the output norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_norm: \n",
      " RMS_NormTensor(\n",
      "    norm_size=tensor(1.5000),\n",
      "    elem_dims=(1,),\n",
      "    unwrapped=FakeTensor(..., size=(10, 8)),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output_norm = norm_map(normed_input, normed_state_dict=normed_state_dict)\n",
    "print('output_norm: \\n', output_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we manually compute, it should be $1 * \\frac{1}{\\sqrt{2}} * 1  * \\frac{1}{\\sqrt{2}} * 1 + 1 = 1.5$. So yay!\n",
    "\n",
    "Note that we get norm type and dim propagation too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex2: build modula norm automatically for regular PyTorch modules\n",
    "\n",
    "To compute the modula norm, we need to get the local \"influence\" of weight norms to output. Fortunately, we can use PyTorch autograd!\n",
    "\n",
    "Let's first specify that the weight norm sizes require gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_state_dict:\n",
      "{'net.0.bias': RMS_NormTensor(norm_size=tensor(0., requires_grad=True), elem_dims=(-1,), ...),\n",
      " 'net.0.weight': RMS_RMS_NormTensor(norm_size=tensor(1., requires_grad=True), elem_dims=(-1, -2), ...),\n",
      " 'net.2.bias': RMS_NormTensor(norm_size=tensor(0., requires_grad=True), elem_dims=(-1,), ...),\n",
      " 'net.2.weight': RMS_RMS_NormTensor(norm_size=tensor(1., requires_grad=True), elem_dims=(-1, -2), ...),\n",
      " 'net.4.bias': RMS_NormTensor(norm_size=tensor(0., requires_grad=True), elem_dims=(-1,), ...),\n",
      " 'net.4.weight': RMS_RMS_NormTensor(norm_size=tensor(1., requires_grad=True), elem_dims=(-1, -2), ...)}\n"
     ]
    }
   ],
   "source": [
    "normed_state_dict = {k: v.norm_size_requires_grad_(True) for k, v in normed_state_dict.items()}\n",
    "print('normed_state_dict:')\n",
    "from pprint import pprint\n",
    "pprint(normed_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_norm: \n",
      " RMS_NormTensor(\n",
      "    norm_size=tensor(1.5000, grad_fn=<AddBackward0>),\n",
      "    elem_dims=(1,),\n",
      "    unwrapped=FakeTensor(..., size=(10, 8)),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output_norm = norm_map(normed_input, normed_state_dict=normed_state_dict)\n",
    "print('output_norm: \\n', output_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `grad_fn`! Now invoke autograd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_norm.norm_size.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity of net.2.weight:\n",
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "sensitivities = {k: v.norm_size.grad for k, v in normed_state_dict.items()}\n",
    "print('sensitivity of net.2.weight:')\n",
    "print(sensitivities['net.2.weight'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mudula norm, we have \n",
    "\n",
    "$$||\\{W_i\\}_i||_M := \\max_i  \\frac{\\text{total\\_mass}}{\\text{mass}_i} \\text{influence}_i ||W_i|| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masses:\n",
      "{'net.0.bias': 0.1,\n",
      " 'net.0.weight': 1,\n",
      " 'net.2.bias': 0.1,\n",
      " 'net.2.weight': 1,\n",
      " 'net.4.bias': 0.1,\n",
      " 'net.4.weight': 1}\n",
      "total_mass: 3.3\n"
     ]
    }
   ],
   "source": [
    "masses = {k: 1 if k.endswith('weight') else 0.1 for k in normed_state_dict}\n",
    "print('masses:')\n",
    "pprint(masses)\n",
    "\n",
    "total_mass = sum(mass.values())\n",
    "print(f'total_mass: {total_mass:g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modula_norm: 1.6500\n"
     ]
    }
   ],
   "source": [
    "modula_norm = max(\n",
    "    total_mass / masses[k] * sensitivities[k] * normed_state_dict[k].norm_size.detach()\n",
    "    for k in normed_state_dict\n",
    ")\n",
    "print(f'modula_norm: {modula_norm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex3: Optimize scaling factors\n",
    "\n",
    "Here the output norm is 1.5, not unit norm. How can we scale the layers so that it becomes unit norm?\n",
    "\n",
    "Let's use the special class `auto_norm.ConstantScaler` to optimize for scaling factors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyResBlockWithScaling(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (1): ConstantScaler()\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (4): ConstantScaler()\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (7): ConstantScaler()\n",
       "  )\n",
       "  (idt_scaler): ConstantScaler()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyResBlockWithScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            auto_norm.ConstantScaler(),  # insert scales at places we want to tune. by default, it is noop\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            auto_norm.ConstantScaler(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            auto_norm.ConstantScaler(),\n",
    "        )\n",
    "        self.idt_scaler = auto_norm.ConstantScaler()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.idt_scaler(x) + self.net(x)\n",
    "\n",
    "\n",
    "scaled_net = MyResBlockWithScaling()\n",
    "norm_map_for_scaled_net = auto_norm.build_norm_map(scaled_net, example_input)\n",
    "scaled_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the state dict contains these new scale factor. We can send any scale factors to a `norm_map` via the normed state dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_normed_state_dict_for_scaled_net(post_linear_scale, idt_scale):\n",
    "    normed_state_dict = {}\n",
    "    for name in scaled_net.state_dict():\n",
    "        if name.endswith('weight'):\n",
    "            normed_state_dict[name] = auto_norm.RMS_RMS_NormTensor(1, elem_dims=(-1, -2))\n",
    "        elif name.endswith('bias'):\n",
    "            normed_state_dict[name] = auto_norm.RMS_NormTensor(0, elem_dims=(-1,))\n",
    "        elif name == 'idt_scaler.scale':\n",
    "            normed_state_dict[name] = idt_scale\n",
    "        elif name.endswith('scale'):\n",
    "            normed_state_dict[name] = post_linear_scale\n",
    "    return normed_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the current output norm is the same as without the scaler (since they default to scale=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_norm: \n",
      " RMS_NormTensor(\n",
      "    norm_size=tensor(1.5000),\n",
      "    elem_dims=(1,),\n",
      "    unwrapped=FakeTensor(..., size=(10, 8)),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "normed_state_dict = build_normed_state_dict_for_scaled_net(post_linear_scale=torch.tensor(1.), idt_scale=torch.tensor(1.))\n",
    "\n",
    "\n",
    "output_norm = norm_map_for_scaled_net(normed_input, normed_state_dict=normed_state_dict)\n",
    "print('output_norm: \\n', output_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's tune the scaling factors so that the output norm becomes 1!\n",
    "\n",
    "First, let's prepare the normed state dict with scale factors that require grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normed_state_dict:\n",
      "{'idt_scaler.scale': tensor(1., requires_grad=True),\n",
      " 'net.0.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.0.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.1.scale': tensor(1., requires_grad=True),\n",
      " 'net.3.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.3.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.4.scale': tensor(1., requires_grad=True),\n",
      " 'net.6.bias': RMS_NormTensor(norm_size=tensor(0.), elem_dims=(-1,), ...),\n",
      " 'net.6.weight': RMS_RMS_NormTensor(norm_size=tensor(1.), elem_dims=(-1, -2), ...),\n",
      " 'net.7.scale': tensor(1., requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "post_linear_scale = torch.tensor(1., requires_grad=True)  # requres grad!\n",
    "idt_scale = torch.tensor(1., requires_grad=True)\n",
    "normed_state_dict = build_normed_state_dict_for_scaled_net(post_linear_scale, idt_scale)\n",
    "print('normed_state_dict:')\n",
    "pprint(normed_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, simply optimize with autograd..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 050: loss=0.0000 output_norm=1.0000\n",
      "iter 100: loss=0.0000 output_norm=1.0000\n",
      "iter 150: loss=0.0000 output_norm=1.0000\n",
      "iter 200: loss=0.0000 output_norm=1.0000\n",
      "post_linear_scale: \n",
      " tensor(0.7549, requires_grad=True)\n",
      "idt_scale: \n",
      " tensor(0.7849, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD([post_linear_scale, idt_scale], lr=0.01)\n",
    "for ii in range(1, 201):\n",
    "    optim.zero_grad()\n",
    "    output_norm = norm_map_for_scaled_net(normed_input, normed_state_dict=normed_state_dict)\n",
    "    loss = F.mse_loss(output_norm.norm_size, torch.tensor(1.))\n",
    "    if ii % 50 == 0:\n",
    "        print(f'iter {ii:03d}: loss={loss:.4f} output_norm={output_norm.norm_size:.4f}')\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print('post_linear_scale: \\n', post_linear_scale)\n",
    "print('idt_scale: \\n', idt_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that they works manually too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_output_norm: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "manual_output_norm = (\n",
    "    (scaler_contribution := post_linear_scale ** 3) *\n",
    "    (relu_contribution := (1 / math.sqrt(2)) ** 2) +\n",
    "    (idt_contribution := idt_scale)\n",
    ")\n",
    "assert torch.allclose(manual_output_norm, torch.tensor(1.))\n",
    "print(f'manual_output_norm: {manual_output_norm:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
